% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hellmer.R
\name{chat_sequential}
\alias{chat_sequential}
\title{Process a batch of prompts in sequence}
\usage{
chat_sequential(chat_model = NULL, ...)
}
\arguments{
\item{chat_model}{ellmer chat model object or function (e.g., \code{ellmer::chat_claude})}

\item{...}{Additional arguments passed to the underlying chat model (e.g., \code{system_prompt})}
}
\value{
A batch object (S7 class) containing
\itemize{
\item prompts: Original input prompts
\item responses: Raw response data for completed prompts
\item completed: Number of successfully processed prompts
\item state_path: Path where batch state is saved
\item type_spec: Type specification used for structured data
\item texts: Function to extract text responses (includes structured data when a type specification is provided)
\item chats: Function to extract chat objects
\item progress: Function to get processing status
\item batch: Function to process a batch of prompts
}
}
\description{
Processes a batch of chat prompts one at a time in sequential order.
Maintains state between runs and can resume interrupted processing.
For parallel processing, use \code{chat_future()}.
}
\section{Batch Method}{

\preformatted{
batch(
  prompts,
  type_spec = NULL,
  judgements = 0,
  state_path = tempfile("chat_", fileext = ".rds"),
  progress = TRUE,
  max_retries = 3L,
  initial_delay = 20,
  max_delay = 80,
  backoff_factor = 2,
  beep = TRUE,
  echo = FALSE,
  ...
)
}

The batch method processes multiple prompts and returns a batch object:
\itemize{
\item prompts: List of prompts to process
\item type_spec: Type specification for structured data extraction
\item judgements: Number of judgements for data extraction accuracy
\item state_path: Path to save state file for resuming interrupted processing
\item progress: Whether to show progress bars (default: TRUE)
\item max_retries: Maximum number of retry attempts for failed requests
\item initial_delay: Initial delay before first retry in seconds
\item max_delay: Maximum delay between retries in seconds
\item backoff_factor: Factor to multiply delay by after each retry
\item beep: Whether to play a sound on completion
\item echo: Whether to display chat outputs (when progress is FALSE)
\item ...: Additional arguments passed to the chat method
}
}

\examples{
\dontshow{if (ellmer::has_credentials("openai")) (if (getRversion() >= "3.4") withAutoprint else force)(\{ # examplesIf}
# Create a sequential chat processor with an object
chat <- chat_sequential(chat_openai(system_prompt = "Reply concisely"))

# Or a function
chat <- chat_sequential(chat_openai, system_prompt = "Reply concisely, one sentence")

# Process a batch of prompts in sequence
batch <- chat$batch(
  list(
    "What is R?",
    "Explain base R versus tidyverse",
    "Explain vectors, lists, and data frames"
  ),
  max_retries = 3L,
  initial_delay = 20,
  beep = TRUE
)

# Process batch with echo enabled (when progress is disabled)
batch <- chat$batch(
  list(
    "What is R?",
    "Explain base R versus tidyverse"
  ),
  progress = FALSE,
  echo = TRUE
)

# Check the progress if interrupted
batch$progress()

# Return the responses
batch$texts()

# Return the chat objects
batch$chats()
\dontshow{\}) # examplesIf}
}
