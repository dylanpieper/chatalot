% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/chatlot.R
\name{chat_sequential}
\alias{chat_sequential}
\title{Process a lot of prompts in sequence}
\usage{
chat_sequential(chat_model = NULL, ...)
}
\arguments{
\item{chat_model}{ellmer chat model object or function (e.g., \code{chat_openai()})}

\item{...}{Additional arguments passed to the underlying chat model (e.g., \code{system_prompt})}
}
\value{
A lot object (S7 class) containing
\itemize{
\item \strong{prompts}: Original input prompts
\item \strong{responses}: Raw response data for completed prompts
\item \strong{completed}: Number of successfully processed prompts
\item \strong{file}: Path where batch state is saved
\item \strong{type}: Type specification used for structured data
\item \strong{texts}: Function to extract text responses or structured data
\item \strong{chats}: Function to extract chat objects
\item \strong{progress}: Function to get processing status
\item \strong{lot}: Function to process a lot of prompts
}
}
\description{
Processes a lot of chat prompts one at a time in sequential order.
Maintains state between runs and can resume interrupted processing.
For parallel processing, use \code{chat_future()}.
}
\section{Lot Method}{

This function provides access to the \code{lot()} method for sequential processing of prompts.
See \code{?lot.sequential_chat} for full details of the method and its parameters.
}

\examples{
\dontshow{if (ellmer::has_credentials("openai")) (if (getRversion() >= "3.4") withAutoprint else force)(\{ # examplesIf}
# Create chat processor
chat <- chat_sequential(chat_openai(system_prompt = "Reply concisely"))

# Process prompts
lot <- chat$lot(
  list(
    "What is R?",
    "Explain base R versus tidyverse",
    "Explain vectors, lists, and data frames"
  )
)


# Check progress if interrupted
lot$progress()

# Return responses
lot$texts()

# Return chat objects
lot$chats()
\dontshow{\}) # examplesIf}
}
