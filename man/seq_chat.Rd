% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/chatalot.R
\name{seq_chat}
\alias{seq_chat}
\title{Create a sequential chat processor}
\usage{
seq_chat(chat_model = NULL, ...)
}
\arguments{
\item{chat_model}{Character string specifying the chat model to use (e.g., "openai/gpt-4.1" or "anthropic/claude-3-5-sonnet-latest").
This creates an ellmer chat object using \code{\link[ellmer:chat-any]{ellmer::chat()}}.}

\item{...}{Additional arguments passed to the underlying chat model (e.g., \code{system_prompt})}
}
\value{
An R6 object with the following methods attached:
\itemize{
\item \verb{$process()}: Function to process multiple prompts sequentially.
Takes a vector or list of prompts and processes them one by one with persistent caching.
Returns a process object containing results and helper functions.
See \code{?process.sequential_chat} for full details of the method and its parameters.
\item \verb{$register_tool()}: Function to register tools that call functions to be used
during chat interactions. Works the same as ellmer's \href{https://ellmer.tidyverse.org/articles/tool-calling.html}{\verb{$register_tool()}}.
}
}
\description{
Access methods to process lots of chat prompts in sequence, or one at a time.
Use this function to process prompts slowly, such as when providers don't allow parallel processing
or have strict rate limits, or when you want to periodically check the responses.
For parallel processing, use \code{future_chat()}.
}
\examples{
\dontshow{if (ellmer::has_credentials("openai")) (if (getRversion() >= "3.4") withAutoprint else force)(\{ # examplesIf}
# Create chat processor
chat <- seq_chat("openai/gpt-4.1")

# Process prompts
response <- chat$process(
  c(
    "What is R?",
    "Explain base R versus tidyverse",
    "Explain vectors, lists, and data frames"
  )
)


# Return responses
response$texts()

# Return chat objects
response$chats()

# Check progress if interrupted
response$progress()
\dontshow{\}) # examplesIf}
}
