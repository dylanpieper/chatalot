% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/chatalot.R
\name{future_chat}
\alias{future_chat}
\title{Process lots of prompts in parallel}
\usage{
future_chat(chat_model = NULL, ...)
}
\arguments{
\item{chat_model}{Character string specifying the chat model to use (e.g., "openai/gpt-4.1" or "anthropic/claude-3-5-sonnet-latest").
This creates an ellmer chat object using \code{\link[ellmer:chat-any]{ellmer::chat()}}.}

\item{...}{Additional arguments passed to the underlying chat model (e.g., \code{system_prompt})}
}
\value{
An R6 object with the following methods attached:
\itemize{
\item \verb{$process()}: Method to process multiple prompts in parallel.
Takes a vector or list of prompts and processes them simultaneously
using multiple workers with persistent caching. Returns a process object
containing results and helper functions. See \code{?process.future_chat} for full details
of the method and its parameters.
\item \verb{$register_tool()}: Function to register tools that call functions to be used
during chat interactions. Works the same as ellmer's \href{https://ellmer.tidyverse.org/articles/tool-calling.html}{\verb{$register_tool()}}.
}
}
\description{
Process lots of chat prompts in parallel using multisession
\href{https://www.futureverse.org}{future} workers.
Use this function to process lots of chat prompts very quickly.
For sequential processing, use \code{seq_chat()}.
}
\examples{
\dontshow{if (interactive() && ellmer::has_credentials("openai")) (if (getRversion() >= "3.4") withAutoprint else force)(\{ # examplesIf}
# Create chat processor
chat <- future_chat("openai/gpt-4.1")

# Process prompts
response <- chat$process(
  c(
    "What is R?",
    "Explain base R versus tidyverse",
    "Explain vectors, lists, and data frames"
  )
)

# Return responses
response$texts()

# Return chat objects
response$chats()

# Check progress if interrupted
response$progress()
\dontshow{\}) # examplesIf}
}
