[{"path":"https://dylanpieper.github.io/chatlot/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 chatlot authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://dylanpieper.github.io/chatlot/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dylan Pieper. Author, maintainer.","code":""},{"path":"https://dylanpieper.github.io/chatlot/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Pieper D (2025). chatlot: Process Lots Chats. R package version 0.1.2, https://dylanpieper.github.io/chatlot/.","code":"@Manual{,   title = {chatlot: Process Lots of Chats},   author = {Dylan Pieper},   year = {2025},   note = {R package version 0.1.2},   url = {https://dylanpieper.github.io/chatlot/}, }"},{"path":"https://dylanpieper.github.io/chatlot/index.html","id":"chatlot-","dir":"","previous_headings":"","what":"Process Lots of Chats","title":"Process Lots of Chats","text":"chatlot synchronously processes lot large language model chats R using ellmer. Easily setup sequential parallel processing workflows advanced features including tool calling, structured data extraction, progress tracking recovery options, quality--life features sound notifications verbosity controls. chatlot similar existing ellmer tools: ellmer::parallel_chat() - Synchronously processes lots chats parallel. tool simple fast limited features option save recover progress. ellmer::batch_chat() - Asynchronously batch processes lots chats select providers. tool 50% cheaper wait 24 hours response.","code":""},{"path":"https://dylanpieper.github.io/chatlot/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Process Lots of Chats","text":"can install development CRAN version package :","code":"# pak::pak(\"dylanpieper/chatlot\") pak::pak(\"chatlot\")"},{"path":"https://dylanpieper.github.io/chatlot/index.html","id":"setup-api-keys","dir":"","previous_headings":"","what":"Setup API Keys","title":"Process Lots of Chats","text":"API keys allow access chat models stored environmental variables. recommend usethis package setup API keys .Renviron OPENAI_API_KEY=-key.","code":"usethis::edit_r_environ(scope = c(\"user\", \"project\"))"},{"path":"https://dylanpieper.github.io/chatlot/index.html","id":"basic-usage","dir":"","previous_headings":"","what":"Basic Usage","title":"Process Lots of Chats","text":"following examples, define chat object reuse across batches.","code":"openai <- chat_openai(system_prompt = \"Reply concisely, one sentence\")"},{"path":"https://dylanpieper.github.io/chatlot/index.html","id":"sequential-processing","dir":"","previous_headings":"Basic Usage","what":"Sequential Processing","title":"Process Lots of Chats","text":"Sequential processing calls one chat time saves data disk. Access responses:","code":"library(chatlot)  chat <- chat_sequential(openai)  prompts <- c(   \"How to have the best vacation in Portugal?\",   \"When is the best time of year to visit Portugal?\",   \"What foods to expect as a tourist in Portugal?\",   \"Which words to know in Portugese as a tourist?\" )  response <- chat$process(prompts) response$texts() #> [1] \"Plan ahead to include a mix of historic cities, coastal escapes,  #> local cuisine, and authentic cultural experiences while keeping time  #> for spontaneous discoveries.\" #>                                                    #> [2] \"The best time to visit Portugal is during the shoulder seasons of spring  #> (March-May) and fall (September-October) when the weather is pleasant and  #> there are fewer crowds.\"        #>                                                      #> [3] \"As a tourist in Portugal, you can expect a rich variety of seafood  #> (like cod and grilled fish), hearty grilled meats, savory stews, delectable  #> pastries such as pastel de nata, and locally produced wines and cheeses.\"  #>               #> [4] \"Essential words include \\\"olá\\\" for hello, \\\"por favor\\\" for please,  #> \\\"obrigado/obrigada\\\" for thank you, \\\"sim\\\" and \\\"não\\\" for yes and no,  #> \\\"desculpe\\\" to apologize, \\\"quanto?\\\" for asking price,  #> and \\\"banheiro\\\" for bathroom.\""},{"path":"https://dylanpieper.github.io/chatlot/index.html","id":"parallel-processing","dir":"","previous_headings":"Basic Usage","what":"Parallel Processing","title":"Process Lots of Chats","text":"⚠️ Parallel processing temporarily unavailable ellmer 0.2.1 due changes API key handling. ✅ Parallel processing work install pak::pak(\"ellmer@0.2.0\"). Parallel processing uses future create multiple R processes (workers) chat time. method improves speed processing. default upper limit number workers parallel::detectCores(). default chunk_size also parallel::detectCores() defines number prompts process time. chat chunk distributed across available R processes. chunk finished, data saved disk. maximum processing speed, set chunk_size number prompts. However, aware data saved disk chats processed, risking data loss additional cost.","code":"chat <- chat_future(openai) response <- chat$process(   prompts,    chunk_size = length(prompts) )"},{"path":[]},{"path":"https://dylanpieper.github.io/chatlot/index.html","id":"tooling","dir":"","previous_headings":"Features","what":"Tooling","title":"Process Lots of Chats","text":"Register use tool/function calling:","code":"weather <- data.frame(   city = c(\"Chicago\", \"NYC\", \"Lisbon\"),   raining = c(\"heavy\", \"none\", \"overcast\"),   temperature = c(\"cool\", \"hot\", \"warm\"),   wind = c(\"strong\", \"weak\", \"strong\") )  get_weather <- function(cities) weather[weather$city %in% cities, ]  chat$register_tool(tool(   get_weather,   \"Report on weather conditions.\",   cities = type_array(\"City names\", type_string()) ))  response <- chat$process(interpolate(\"Give me a weather update for {{weather$city}}?\"))  response$texts() #> [1] \"In Chicago, it's cool with heavy rain and strong winds.\"                    #> [2] \"The current weather in NYC is hot with no rain and light winds.\"            #> [3] \"Lisbon currently has an overcast sky, warm temperatures, and strong winds.\""},{"path":"https://dylanpieper.github.io/chatlot/index.html","id":"structured-data-extraction","dir":"","previous_headings":"Features","what":"Structured Data Extraction","title":"Process Lots of Chats","text":"Extract structured data using type specifications:","code":"prompts <- c(   \"I go by Alex. 42 years on this planet and counting.\",   \"Pleased to meet you! I'm Jamal, age 27.\",   \"They call me Li Wei. Nineteen years young.\",   \"Fatima here. Just celebrated my 35th birthday last week.\",   \"The name's Robert - 51 years old and proud of it.\",   \"Kwame here - just hit the big 5-0 this year.\" )  response <- chat$process(   prompts,   type = type_object(     name = type_string(),     age = type_number()   ) )  response$texts() #>     name age #> 1   Alex  42 #> 2  Jamal  27 #> 3 Li Wei  19 #> 4 Fatima  35 #> 5 Robert  51 #> 6  Kwame  50"},{"path":"https://dylanpieper.github.io/chatlot/index.html","id":"progress-tracking-and-recovery","dir":"","previous_headings":"Features","what":"Progress Tracking and Recovery","title":"Process Lots of Chats","text":"Progress tracked response$progress() saved .rds file disk, allows easily resume interrupted operations: file defined, temporary file created default.","code":"response <- chat$process(prompts, file = \"chat.rds\")"},{"path":"https://dylanpieper.github.io/chatlot/index.html","id":"sound-notifications","dir":"","previous_headings":"Features","what":"Sound Notifications","title":"Process Lots of Chats","text":"Toggle sound notifications completion, interruption, error:","code":"response <- chat$process(prompts, beep = TRUE)"},{"path":"https://dylanpieper.github.io/chatlot/index.html","id":"verbosity","dir":"","previous_headings":"Features","what":"Verbosity","title":"Process Lots of Chats","text":"default, chat echo set FALSE show progress bar. However, can still configure echo first setting progress FALSE:","code":"prompts <- c(   \"What is R?\",   \"Explain base R versus tidyverse\" )  response <- chat$process(   prompts,   progress = FALSE,   echo = TRUE ) #> R is a programming language and software environment used for  #> statistical computing and graphics. #>  #> Base R consists of the core functionalities built into R,  #> while tidyverse is a collection of packages that offer a more #> consistent, readable, and streamlined approach to data manipulation,  #> visualization, and analysis."},{"path":"https://dylanpieper.github.io/chatlot/index.html","id":"methods","dir":"","previous_headings":"Features","what":"Methods","title":"Process Lots of Chats","text":"progress(): Returns processing status texts(): Returns response texts format input prompts (.e., list prompts provided list, character vector prompts provided vector). type provided, list one element prompt. type consistent object, returns data frame one row prompt, one column property. chats(): Returns list chat objects","code":""},{"path":"https://dylanpieper.github.io/chatlot/index.html","id":"further-reading","dir":"","previous_headings":"","what":"Further Reading","title":"Process Lots of Chats","text":"Batch Compare Similarity LLM Responses R (Blog Post)","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/chat_future.html","id":null,"dir":"Reference","previous_headings":"","what":"Process a lot of prompts in parallel — chat_future","title":"Process a lot of prompts in parallel — chat_future","text":"Processes lot chat prompts using parallel workers. Splits prompts chunks processing maintaining state. sequential processing, use chat_sequential().","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/chat_future.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process a lot of prompts in parallel — chat_future","text":"","code":"chat_future(chat_model = NULL, ...)"},{"path":"https://dylanpieper.github.io/chatlot/reference/chat_future.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process a lot of prompts in parallel — chat_future","text":"chat_model ellmer chat model object function (e.g., chat_openai()) ... Additional arguments passed underlying chat model (e.g., system_prompt)","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/chat_future.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process a lot of prompts in parallel — chat_future","text":"process object (S7 class) containing: prompts: Original input prompts responses: Raw response data completed prompts completed: Number successfully processed prompts file: Path batch state saved type: Type specification used structured data texts: Function extract text responses structured data chats: Function extract chat objects progress: Function get processing status process: Function process lot prompts","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/chat_future.html","id":"process-method","dir":"Reference","previous_headings":"","what":"Process Method","title":"Process a lot of prompts in parallel — chat_future","text":"function provides access process() method parallel processing prompts. See ?process.future_chat full details method parameters.","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/chat_future.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process a lot of prompts in parallel — chat_future","text":"","code":"if (FALSE) { # interactive() && ellmer::has_credentials(\"openai\") # Create chat processor chat <- chat_future(chat_openai(system_prompt = \"Reply concisely\"))  # Process prompts response <- chat$process(   list(     \"What is R?\",     \"Explain base R versus tidyverse\",     \"Explain vectors, lists, and data frames\"   ) )  # Return responses response$texts()  # Return chat objects response$chats()  # Check progress if interrupted response$progress() }"},{"path":"https://dylanpieper.github.io/chatlot/reference/chat_sequential.html","id":null,"dir":"Reference","previous_headings":"","what":"Process a lot of prompts in sequence — chat_sequential","title":"Process a lot of prompts in sequence — chat_sequential","text":"Processes lot chat prompts one time sequential order. Maintains state runs can resume interrupted processing. parallel processing, use chat_future().","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/chat_sequential.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process a lot of prompts in sequence — chat_sequential","text":"","code":"chat_sequential(chat_model = NULL, ...)"},{"path":"https://dylanpieper.github.io/chatlot/reference/chat_sequential.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process a lot of prompts in sequence — chat_sequential","text":"chat_model ellmer chat model object function (e.g., chat_openai()) ... Additional arguments passed underlying chat model (e.g., system_prompt)","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/chat_sequential.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process a lot of prompts in sequence — chat_sequential","text":"process object (S7 class) containing prompts: Original input prompts responses: Raw response data completed prompts completed: Number successfully processed prompts file: Path batch state saved type: Type specification used structured data texts: Function extract text responses structured data chats: Function extract chat objects progress: Function get processing status process: Function process lot prompts","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/chat_sequential.html","id":"process-method","dir":"Reference","previous_headings":"","what":"Process Method","title":"Process a lot of prompts in sequence — chat_sequential","text":"function provides access process() method sequential processing prompts. See ?process.sequential_chat full details method parameters.","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/chat_sequential.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process a lot of prompts in sequence — chat_sequential","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create chat processor chat <- chat_sequential(chat_openai(system_prompt = \"Reply concisely\"))  # Process prompts response <- chat$process(   list(     \"What is R?\",     \"Explain base R versus tidyverse\",     \"Explain vectors, lists, and data frames\"   ) )   # Return responses response$texts()  # Return chat objects response$chats()  # Check progress if interrupted response$progress() }"},{"path":"https://dylanpieper.github.io/chatlot/reference/chats.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract chat objects from a process result — chats","title":"Extract chat objects from a process result — chats","text":"Extract chat objects process result","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/chats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract chat objects from a process result — chats","text":"","code":"chats(x, ...)"},{"path":"https://dylanpieper.github.io/chatlot/reference/chats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract chat objects from a process result — chats","text":"x process object ... Additional arguments","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/chats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract chat objects from a process result — chats","text":"list chat objects","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/chats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract chat objects from a process result — chats","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create a chat processor chat <- chat_sequential(chat_openai())  # Process a batch of prompts process_result <- chat$process(list(   \"What is R?\",   \"Explain base R versus tidyverse\",   \"Explain vectors, lists, and data frames\" ))  # Return the chat objects process_result$chats() }"},{"path":"https://dylanpieper.github.io/chatlot/reference/process.future_chat.html","id":null,"dir":"Reference","previous_headings":"","what":"Process a lot of prompts with a parallel chat — process.future_chat","title":"Process a lot of prompts with a parallel chat — process.future_chat","text":"Process lot prompts parallel chat","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/process.future_chat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process a lot of prompts with a parallel chat — process.future_chat","text":"","code":"process.future_chat(   chat_env,   prompts,   type = NULL,   file = tempfile(\"chat_\", fileext = \".rds\"),   workers = NULL,   chunk_size = parallel::detectCores(),   max_chunk_attempts = 3L,   beep = TRUE,   progress = TRUE,   echo = FALSE,   ... )"},{"path":"https://dylanpieper.github.io/chatlot/reference/process.future_chat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process a lot of prompts with a parallel chat — process.future_chat","text":"chat_env chat environment chat_future prompts List prompts process type Type specification structured data extraction file Path save state file workers Number parallel workers (default upper limit parallel::detectCores()) chunk_size Number prompts worker processes time max_chunk_attempts Maximum retries per failed chunk beep Whether play sound completion progress Whether show progress bars echo Whether display chat outputs (progress FALSE) ... Additional arguments passed chat method","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/process.future_chat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process a lot of prompts with a parallel chat — process.future_chat","text":"process object processed results","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/process.html","id":null,"dir":"Reference","previous_headings":"","what":"Process result class for managing chat processing results — process","title":"Process result class for managing chat processing results — process","text":"Process result class managing chat processing results","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/process.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process result class for managing chat processing results — process","text":"","code":"process(   prompts = list(),   responses = list(),   completed = integer(0),   file = character(0),   type = NULL,   progress = logical(0),   input_type = character(0),   chunk_size = integer(0),   workers = integer(0),   beep = logical(0),   echo = logical(0),   state = list() )"},{"path":"https://dylanpieper.github.io/chatlot/reference/process.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process result class for managing chat processing results — process","text":"prompts List prompts process responses List store responses completed Integer indicating number completed prompts file Path save state file (.rds) type Type specification structured data extraction progress Whether show progress bars (default: TRUE) input_type Type input (\"vector\" \"list\") chunk_size Size chunks parallel processing workers Number parallel workers beep Play sound completion (default: TRUE) echo Whether echo messages processing (default: FALSE) state Internal state tracking","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/process.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process result class for managing chat processing results — process","text":"Returns S7 class object class \"process\" represents collection prompts responses chat models. object contains input parameters properties provides methods : Extracting text responses via texts() (includes structured data type specification provided) Accessing full chat objects via chats() Tracking processing progress via progress() process object manages prompt processing tracks completion status.","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/process.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process result class for managing chat processing results — process","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create a chat processor chat <- chat_sequential(chat_openai())  # Process a batch of prompts process_result <- chat$process(list(   \"What is R?\",   \"Explain base R versus tidyverse\",   \"Explain vectors, lists, and data frames\" ))  # Check the progress if interrupted process_result$progress()  # Return the responses as a vector or list process_result$texts()  # Return the chat objects process_result$chats() }"},{"path":"https://dylanpieper.github.io/chatlot/reference/process.sequential_chat.html","id":null,"dir":"Reference","previous_headings":"","what":"Process a lot of prompts with a sequential chat — process.sequential_chat","title":"Process a lot of prompts with a sequential chat — process.sequential_chat","text":"Process lot prompts sequential chat","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/process.sequential_chat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process a lot of prompts with a sequential chat — process.sequential_chat","text":"","code":"process.sequential_chat(   chat_env,   prompts,   type = NULL,   file = tempfile(\"chat_\", fileext = \".rds\"),   progress = TRUE,   beep = TRUE,   echo = FALSE,   ... )"},{"path":"https://dylanpieper.github.io/chatlot/reference/process.sequential_chat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process a lot of prompts with a sequential chat — process.sequential_chat","text":"chat_env chat environment chat_sequential prompts List prompts process type Type specification structured data extraction file Path save state file (.rds) progress Whether show progress bars beep Whether play sound completion echo Whether display chat outputs (progress FALSE) ... Additional arguments passed chat method","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/process.sequential_chat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process a lot of prompts with a sequential chat — process.sequential_chat","text":"process object processed results","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/progress.html","id":null,"dir":"Reference","previous_headings":"","what":"Get progress information from a process result — progress","title":"Get progress information from a process result — progress","text":"Get progress information process result","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/progress.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get progress information from a process result — progress","text":"","code":"progress(x, ...)"},{"path":"https://dylanpieper.github.io/chatlot/reference/progress.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get progress information from a process result — progress","text":"x process object ... Additional arguments passed methods","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/progress.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get progress information from a process result — progress","text":"list containing progress details","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/progress.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get progress information from a process result — progress","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create a chat processor chat <- chat_sequential(chat_openai())  # Process a batch of prompts process_result <- chat$process(list(   \"What is R?\",   \"Explain base R versus tidyverse\",   \"Explain vectors, lists, and data frames\" ))  # Check the progress process_result$progress() }"},{"path":"https://dylanpieper.github.io/chatlot/reference/texts.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract texts or structured data from a process result — texts","title":"Extract texts or structured data from a process result — texts","text":"Extract texts structured data process result","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/texts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract texts or structured data from a process result — texts","text":"","code":"texts(x, ...)"},{"path":"https://dylanpieper.github.io/chatlot/reference/texts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract texts or structured data from a process result — texts","text":"x process object ... Additional arguments passed methods","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/texts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract texts or structured data from a process result — texts","text":"character vector list text responses. type specification provided batch, return structured data.","code":""},{"path":"https://dylanpieper.github.io/chatlot/reference/texts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract texts or structured data from a process result — texts","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create a chat processor chat <- chat_sequential(chat_openai())  # Process a batch of prompts process_result <- chat$process(list(   \"What is R?\",   \"Explain base R versus tidyverse\",   \"Explain vectors, lists, and data frames\" ))  # Extract text responses process_result$texts() }"},{"path":[]},{"path":"https://dylanpieper.github.io/chatlot/news/index.html","id":"new-features-0-1-2","dir":"Changelog","previous_headings":"","what":"New Features","title":"chatlot 0.1.2","text":"chat_future() now uses uses CPU cores * 5 default chunk size $batch() gains progress addition echo ... passed chat call","code":""},{"path":[]},{"path":"https://dylanpieper.github.io/chatlot/news/index.html","id":"lifecycle-changes-0-1-2","dir":"Changelog","previous_headings":"","what":"Lifecycle changes","title":"chatlot 0.1.2","text":"Removed timeout feature ’s better handled option(ellmer_timeout_s = 120) ellmer 0.1.1 Moved parameters chat_sequential() chat_future() $batch() except chat_model ...","code":""},{"path":[]},{"path":"https://dylanpieper.github.io/chatlot/news/index.html","id":"new-features-0-1-1","dir":"Changelog","previous_headings":"","what":"New features","title":"chatlot 0.1.1","text":"Removed structured_data() method texts() now handles structured data responses Updated package documentation better organization clarity","code":""},{"path":[]},{"path":"https://dylanpieper.github.io/chatlot/news/index.html","id":"new-features-0-1-0","dir":"Changelog","previous_headings":"","what":"New features","title":"chatlot 0.1.0","text":"Initial CRAN submission","code":""}]
