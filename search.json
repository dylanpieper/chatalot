[{"path":"https://dylanpieper.github.io/hellmer/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 hellmer authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://dylanpieper.github.io/hellmer/articles/using-chat-models.html","id":"method-1-passing-a-function","dir":"Articles","previous_headings":"","what":"Method 1: Passing a Function","title":"Using Ellmer Chat Models","text":"first method pass ellmer chat model function directly. preferred method lets hellmer setup model, specifically setting echo = \"none\" cleaner console output: case, hellmer : Recognize chat_model function Setup model echo = \"none\" additional parameters provide Use newly created model batch processing","code":"library(hellmer)  # Sequential processing chat <- chat_sequential(   chat_model = chat_claude,   system_prompt = \"Reply concisely\" )  # Parallel processing chat <- chat_future(   chat_model = chat_claude,   system_prompt = \"Reply concisely\",   workers = 4 )"},{"path":"https://dylanpieper.github.io/hellmer/articles/using-chat-models.html","id":"method-2-passing-an-object","dir":"Articles","previous_headings":"","what":"Method 2: Passing an Object","title":"Using Ellmer Chat Models","text":"second method pass chat model object. useful need control model configuration want reuse existing model: case, hellmer : Recognize chat_model object Use model -existing configuration","code":"library(hellmer)  # Create and configure a chat model claude <- chat_claude(   model = \"claude-3-7-sonnet-latest\",   system_prompt = \"Reply concisely\",   echo = \"none\",   max_tokens = 1000 )  # Sequential processing chat <- chat_sequential(chat_model = claude)  # Parallel processing chat <- chat_future(   chat_model = claude,   workers = 4 )"},{"path":"https://dylanpieper.github.io/hellmer/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dylan Pieper. Author, maintainer.","code":""},{"path":"https://dylanpieper.github.io/hellmer/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Pieper D (2025). hellmer: Batch Processing Chat Models. R package version 0.1.0, https://dylanpieper.github.io/hellmer/.","code":"@Manual{,   title = {hellmer: Batch Processing for Chat Models},   author = {Dylan Pieper},   year = {2025},   note = {R package version 0.1.0},   url = {https://dylanpieper.github.io/hellmer/}, }"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"hellmer-","dir":"","previous_headings":"","what":"Batch Processing for Chat Models","title":"Batch Processing for Chat Models","text":"hellmer enables sequential parallel batch processing chat models ellmer.","code":""},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Batch Processing for Chat Models","text":"Process multiple chat interactions : Tooling structured data extraction State persistence recovery Progress tracking Configurable output verbosity Automatic retry backoff Timeout handling Sound notifications","code":""},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Batch Processing for Chat Models","text":"","code":"devtools::install_github(\"dylanpieper/hellmer\")"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"load-package","dir":"","previous_headings":"","what":"Load Package","title":"Batch Processing for Chat Models","text":"Run library(hellmer) load package attach ellmer easy access chat models. finish instructions setting API key, ’ll provide RStudio approach started alternative methods:","code":""},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"set-api-key","dir":"","previous_headings":"","what":"Set API Key","title":"Batch Processing for Chat Models","text":"recommend usethis package add API keys .Renviron OPENAI_API_KEY=-key.","code":"usethis::edit_r_environ(scope = c(\"user\", \"project\"))"},{"path":[]},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"sequential-processing","dir":"","previous_headings":"Basic Usage","what":"Sequential Processing","title":"Batch Processing for Chat Models","text":"","code":"chat <- chat_sequential(chat_openai,                          system_prompt = \"Reply concisely, one sentence\")  prompts <- list(   \"What is R?\",   \"Explain base R versus tidyverse\",   \"Explain vectors, lists, and data frames\",   \"How do environments work in R?\",   \"Compare R and Python for data analysis\",   \"Explain lazy evaluation in R\",   \"What are R's apply functions?\",   \"How do R packages work?\",   \"Explain R's object-oriented programming systems.\",   \"What are closures in R?\",   \"Describe R memory management\",   \"How does R handle missing values?\",   \"Explain R's integration with C++\",   \"Compare dplyr and data.table approaches\",   \"What are R formulas and when to use them?\" ) result <- chat$batch(prompts)  result$progress() result$texts() result$chats()"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"parallel-processing","dir":"","previous_headings":"Basic Usage","what":"Parallel Processing","title":"Batch Processing for Chat Models","text":"","code":"chat <- chat_future(chat_openai,                      system_prompt = \"Reply concisely, one sentence\")"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"performance-vs-safety-trade-off","dir":"","previous_headings":"Basic Usage > Parallel Processing","what":"Performance vs Safety Trade-Off","title":"Batch Processing for Chat Models","text":"using parallel processing chat_future, ’s trade-performance safety: Maximum Performance: Setting chunk_size equal number prompts results 4-5x faster processing speed Maximum Safety: Using smaller chunk_size ensures state saved frequently, allowing recovery something goes wrong (default: number prompts / 10)","code":"chat$batch(prompts, chunk_size = length(prompts))"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"naming-note","dir":"","previous_headings":"Basic Usage > Parallel Processing","what":"Naming Note","title":"Batch Processing for Chat Models","text":"chat_future isn’t named chat_parallel latter included ellmer (#143).","code":""},{"path":[]},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"tooling","dir":"","previous_headings":"Features","what":"Tooling","title":"Batch Processing for Chat Models","text":"Register use tools/function calling:","code":"square_number <- function(num) num^2  chat$register_tool(tool(   square_number,   \"Calculates the square of a given number\",   num = type_integer(\"The number to square\") ))  prompts <- list(   \"What is the square of 3?\",   \"Calculate the square of 5.\" )"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"structured-data-extraction","dir":"","previous_headings":"Features","what":"Structured Data Extraction","title":"Batch Processing for Chat Models","text":"Extract structured data using type specifications:","code":"type_sentiment <- type_object(   \"Extract sentiment scores\",   positive_score = type_number(\"Positive sentiment score, 0.0 to 1.0\"),   negative_score = type_number(\"Negative sentiment score, 0.0 to 1.0\"),   neutral_score = type_number(\"Neutral sentiment score, 0.0 to 1.0\") )  prompts <- list(   \"I love this product! It's amazing!\",   \"This is okay, nothing special.\",   \"Terrible experience, very disappointed.\" )  result <- chat$batch(prompts, type_spec = type_sentiment) structured_data <- result$structured_data()"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"state-management","dir":"","previous_headings":"Features","what":"State Management","title":"Batch Processing for Chat Models","text":"Batch processing automatically saves state can resume interrupted operations: state_path defined, temporary file created default.","code":"result <- chat$batch(prompts, state_path = \"chat_state.rds\")"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"output-control","dir":"","previous_headings":"Features","what":"Output Control","title":"Batch Processing for Chat Models","text":"Control verbosity echo parameter (sequential ): \"none\": Silent operation progress bar \"text\": Show chat responses \"\": Show prompts responses","code":"chat <- chat_sequential(   chat_openai,    echo = \"none\" )"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"automatic-retry","dir":"","previous_headings":"Features","what":"Automatic Retry","title":"Batch Processing for Chat Models","text":"Automatically retry failed requests backoff, serves wide guardrail errors ellmer httr2 serve narrow guardrail specific API limits: request fails, code : Wait initial_delay Retry request fails , wait (delay × backoff_factor) Continue success max_retries reached code detects authorization API key issue, stop immediately.","code":"chat <- chat_sequential(   chat_openai,         # Ellmer chat model   max_retries = 3,     # Maximum retry attempts   initial_delay = 20,  # Initial delay in seconds   max_delay = 60,      # Maximum delay between retries   backoff_factor = 2   # Multiply delay by this factor after each retry )"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"timeout-handling","dir":"","previous_headings":"Features","what":"Timeout Handling","title":"Batch Processing for Chat Models","text":"timeout parameter specifies maximum time wait response chat model prompt. However, parameter still limited timeouts propagated chat model functions.","code":"chat <- chat_future(   chat_openai,   system_prompt = \"Reply concisely, one sentence\"   timeout = 60 )"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"sound-notifications","dir":"","previous_headings":"Features","what":"Sound Notifications","title":"Batch Processing for Chat Models","text":"Toggle sound notifications batch completion, interruption, error:","code":"chat <- chat_sequential(   chat_openai,   beep = TRUE )"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"results-methods","dir":"","previous_headings":"Features","what":"Results Methods","title":"Batch Processing for Chat Models","text":"texts(): Returns response texts format input prompts (.e., list prompts provided list, character vector prompts provided vector) chats(): Returns list chat objects progress(): Returns processing statistics structured_data(): Returns extracted structured data (type_spec provided)","code":""},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"further-reading","dir":"","previous_headings":"","what":"Further Reading","title":"Batch Processing for Chat Models","text":"Using Ellmer Chat Models: wondering can use chat_openai() user-defined object instead chat_openai function? course can! Learn two methods default interface.","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Batch class for managing chat processing — batch","title":"Batch class for managing chat processing — batch","text":"Batch class managing chat processing","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Batch class for managing chat processing — batch","text":"","code":"batch(   prompts = list(),   responses = list(),   completed = integer(0),   state_path = character(0),   type_spec = NULL,   echo = character(0),   input_type = character(0),   max_retries = integer(0),   initial_delay = integer(0),   max_delay = integer(0),   backoff_factor = integer(0),   chunk_size = integer(0),   workers = integer(0),   plan = character(0),   state = list() )"},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Batch class for managing chat processing — batch","text":"prompts List prompts process responses List store responses completed Integer indicating number completed prompts state_path Path save state file type_spec Type specification structured data extraction echo Level output display (\"none\", \"text\", \"\") input_type Type input (\"vector\" \"list\") max_retries Maximum number retry attempts initial_delay Initial delay first retry max_delay Maximum delay retries backoff_factor Factor multiply delay retry chunk_size Size chunks parallel processing workers Number parallel workers plan Parallel backend plan state Internal state tracking","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Batch class for managing chat processing — batch","text":"Returns S7 class object class \"batch\" represents collection prompts responses chat models. object contains input parameters properties provides methods : Extracting text responses via texts() Accessing full chat objects via chats() Tracking processing progress via progress() Extracting structured data via structured_data() type specification provided batch object manages prompt processing, tracks completion status, handles retries failed requests.","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Batch class for managing chat processing — batch","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create a chat processor chat <- chat_sequential(chat_openai())  # Process a batch of prompts batch <- chat$batch(list(   \"What is R?\",   \"Explain base R versus tidyverse\",   \"Explain vectors, lists, and data frames\" ))  # Check the progress if interrupted batch$progress()  # Return the responses as a vector or list batch$texts()  # Return the chat objects batch$chats() }"},{"path":"https://dylanpieper.github.io/hellmer/reference/capture.html","id":null,"dir":"Reference","previous_headings":"","what":"Capture chat model response with proper handling — capture","title":"Capture chat model response with proper handling — capture","text":"Capture chat model response proper handling","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/capture.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Capture chat model response with proper handling — capture","text":"","code":"capture(original_chat, prompt, type_spec = NULL, echo = \"text\")"},{"path":"https://dylanpieper.github.io/hellmer/reference/capture.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Capture chat model response with proper handling — capture","text":"original_chat Original chat model object prompt Prompt text type_spec Type specification structured data echo Echo level (\"none\", \"text\", \"\")","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/capture.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Capture chat model response with proper handling — capture","text":"List containing response information","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/capture_with_retry.html","id":null,"dir":"Reference","previous_headings":"","what":"Capture chat model response with proper handling and retries — capture_with_retry","title":"Capture chat model response with proper handling and retries — capture_with_retry","text":"Capture chat model response proper handling retries","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/capture_with_retry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Capture chat model response with proper handling and retries — capture_with_retry","text":"","code":"capture_with_retry(   original_chat,   prompt,   type_spec = NULL,   echo = \"text\",   max_retries = 3L,   initial_delay = 1,   max_delay = 32,   backoff_factor = 2,   timeout = 60 )"},{"path":"https://dylanpieper.github.io/hellmer/reference/capture_with_retry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Capture chat model response with proper handling and retries — capture_with_retry","text":"original_chat Original chat model object prompt Prompt text type_spec Type specification structured data echo Echo level (\"none\", \"text\", \"\") max_retries Maximum number retry attempts initial_delay Initial delay seconds first retry max_delay Maximum delay seconds retries backoff_factor Factor multiply delay retry","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/capture_with_retry.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Capture chat model response with proper handling and retries — capture_with_retry","text":"List containing response information","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_future.html","id":null,"dir":"Reference","previous_headings":"","what":"Process a batch of prompts in parallel — chat_future","title":"Process a batch of prompts in parallel — chat_future","text":"Processes batch chat prompts using parallel workers. Splits prompts chunks processing maintaining state. sequential processing, use chat_sequential().","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_future.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process a batch of prompts in parallel — chat_future","text":"","code":"chat_future(   chat_model = NULL,   workers = parallel::detectCores(),   plan = \"multisession\",   chunk_size = NULL,   max_chunk_attempts = 3L,   max_retries = 3L,   initial_delay = 20,   max_delay = 60,   backoff_factor = 2,   timeout = 60,   beep = TRUE,   ... )"},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_future.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process a batch of prompts in parallel — chat_future","text":"chat_model ellmer chat model function object (e.g., ellmer::chat_claude) workers Number parallel workers use (default: number CPU cores) plan Processing strategy use: \"multisession\" separate R sessions \"multicore\" forked processes (default: \"multisession\") chunk_size Number prompts process parallel time (default: 10% number prompts) max_chunk_attempts Maximum number retry attempts failed chunks (default: 3L) max_retries Maximum number retry attempts per prompt (default: 3L) initial_delay Initial delay seconds first retry (default: 20) max_delay Maximum delay seconds retries (default: 60) backoff_factor Factor multiply delay retry (default: 2) timeout Maximum time seconds wait prompt response (default: 2) beep Logical play sound batch completion, interruption, error (default: TRUE) ... Additional arguments passed underlying chat model (e.g., system_prompt)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_future.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process a batch of prompts in parallel — chat_future","text":"batch object (S7 class) containing: prompts: Original input prompts responses: Raw response data completed prompts completed: Number successfully processed prompts state_path: Path batch state saved type_spec: Type specification used structured data texts: Function extract text responses chats: Function extract chat objects progress: Function get processing status structured_data: Function extract structured data (type_spec provided)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_future.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process a batch of prompts in parallel — chat_future","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create a parallel chat processor chat <- chat_future(chat_openai, system_prompt = \"Reply concisely, one sentence\")  # Process a batch of prompts in parallel batch <- chat$batch(list(   \"What is R?\",   \"Explain base R versus tidyverse\",   \"Explain vectors, lists, and data frames\" ))  # Check the progress if interrupted batch$progress()  # Return the responses as a vector or list batch$texts()  # Return the chat objects batch$chats() }"},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_sequential.html","id":null,"dir":"Reference","previous_headings":"","what":"Process a batch of prompts in sequence — chat_sequential","title":"Process a batch of prompts in sequence — chat_sequential","text":"Processes batch chat prompts one time sequential order. Maintains state runs can resume interrupted processing. parallel processing, use chat_future().","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_sequential.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process a batch of prompts in sequence — chat_sequential","text":"","code":"chat_sequential(   chat_model = NULL,   echo = \"none\",   max_retries = 3L,   initial_delay = 20,   max_delay = 60,   backoff_factor = 2,   timeout = 60,   beep = TRUE,   ... )"},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_sequential.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process a batch of prompts in sequence — chat_sequential","text":"chat_model ellmer chat model function object (e.g., ellmer::chat_claude) echo Level output display: \"none\" silent operation, \"text\" response text , \"\" full interaction (default: \"none\") max_retries Maximum number retry attempts per prompt (default: 3L) initial_delay Initial delay seconds first retry (default: 20) max_delay Maximum delay seconds retries (default: 60) backoff_factor Factor multiply delay retry (default: 2) timeout Maximum time seconds wait prompt response (default: 60) beep Logical play sound batch completion, interruption, error (default: TRUE) ... Additional arguments passed underlying chat model (e.g., system_prompt)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_sequential.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process a batch of prompts in sequence — chat_sequential","text":"batch object (S7 class) containing prompts: Original input prompts responses: Raw response data completed prompts completed: Number successfully processed prompts state_path: Path batch state saved type_spec: Type specification used structured data texts: Function extract text responses chats: Function extract chat objects progress: Function get processing status structured_data: Function extract structured data (type_spec provided)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_sequential.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process a batch of prompts in sequence — chat_sequential","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create a sequential chat processor chat <- chat_sequential(chat_openai, system_prompt = \"Reply concisely, one sentence\")  # Process a batch of prompts in sequence batch <- chat$batch(list(   \"What is R?\",   \"Explain base R versus tidyverse\",   \"Explain vectors, lists, and data frames\" ))  # Check the progress if interrupted batch$progress()  # Return the responses as a vector or list batch$texts()  # Return the chat objects batch$chats() }"},{"path":"https://dylanpieper.github.io/hellmer/reference/chats.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract chat objects from a batch result — chats","title":"Extract chat objects from a batch result — chats","text":"Extract chat objects batch result Extract chat objects batch result","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract chat objects from a batch result — chats","text":"","code":"chats(x, ...)"},{"path":"https://dylanpieper.github.io/hellmer/reference/chats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract chat objects from a batch result — chats","text":"x batch object ... Additional arguments passed methods","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract chat objects from a batch result — chats","text":"list chat objects list chat objects","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract chat objects from a batch result — chats","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create a chat processor chat <- chat_sequential(chat_openai())  # Process a batch of prompts batch <- chat$batch(list(   \"What is R?\",   \"Explain base R versus tidyverse\",   \"Explain vectors, lists, and data frames\" ))  # Return the chat objects batch$chats() }"},{"path":"https://dylanpieper.github.io/hellmer/reference/create_auth_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a standardized authentication error — create_auth_error","title":"Create a standardized authentication error — create_auth_error","text":"Create standardized authentication error","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/create_auth_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a standardized authentication error — create_auth_error","text":"","code":"create_auth_error(original_error)"},{"path":"https://dylanpieper.github.io/hellmer/reference/create_auth_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a standardized authentication error — create_auth_error","text":"original_error Original error message condition","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/create_auth_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a standardized authentication error — create_auth_error","text":"Structured error information","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/create_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Create results object from batch — create_results","title":"Create results object from batch — create_results","text":"Create results object batch","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/create_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create results object from batch — create_results","text":"","code":"create_results(result)"},{"path":"https://dylanpieper.github.io/hellmer/reference/create_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create results object from batch — create_results","text":"result Batch object","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/create_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create results object from batch — create_results","text":"Results object class \"batch\"","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/finish_successful_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Finish successful batch processing — finish_successful_batch","title":"Finish successful batch processing — finish_successful_batch","text":"Called successful completion batch processing update progress indicators provide feedback","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/finish_successful_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finish successful batch processing — finish_successful_batch","text":"","code":"finish_successful_batch(pb, beep)"},{"path":"https://dylanpieper.github.io/hellmer/reference/finish_successful_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finish successful batch processing — finish_successful_batch","text":"pb Progress bar object beep Logical; whether play success sound","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/finish_successful_batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Finish successful batch processing — finish_successful_batch","text":"NULL (invisibly)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/handle_batch_interrupt.html","id":null,"dir":"Reference","previous_headings":"","what":"Handle batch interruption — handle_batch_interrupt","title":"Handle batch interruption — handle_batch_interrupt","text":"Handle batch interruption","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/handle_batch_interrupt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Handle batch interruption — handle_batch_interrupt","text":"","code":"handle_batch_interrupt(result, beep)"},{"path":"https://dylanpieper.github.io/hellmer/reference/handle_batch_interrupt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Handle batch interruption — handle_batch_interrupt","text":"result batch object containing processing state beep Logical indicating whether play sound","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/handle_batch_interrupt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Handle batch interruption — handle_batch_interrupt","text":"NULL (called side effects)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/hellmer-package.html","id":null,"dir":"Reference","previous_headings":"","what":"hellmer: Batch Processing for Chat Models — hellmer-package","title":"hellmer: Batch Processing for Chat Models — hellmer-package","text":"Provides tools efficient batch processing multiple chat model interactions. Building 'ellmer' package, enables sequential parallel processing chat completions robust error handling, progress tracking, retry capabilities. package implements methods distributing workloads across multiple R sessions cores using 'future' framework, managing authentication errors, capturing structured results large batches prompts.","code":""},{"path":[]},{"path":"https://dylanpieper.github.io/hellmer/reference/hellmer-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"hellmer: Batch Processing for Chat Models — hellmer-package","text":"Maintainer: Dylan Pieper dylanpieper@gmail.com","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/is_auth_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if an error is an authentication error — is_auth_error","title":"Check if an error is an authentication error — is_auth_error","text":"Check error authentication error","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/is_auth_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if an error is an authentication error — is_auth_error","text":"","code":"is_auth_error(error)"},{"path":"https://dylanpieper.github.io/hellmer/reference/is_auth_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if an error is an authentication error — is_auth_error","text":"error Error message condition","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/is_auth_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if an error is an authentication error — is_auth_error","text":"TRUE authentication error, FALSE otherwise","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process.html","id":null,"dir":"Reference","previous_headings":"","what":"Process batch of prompts with progress tracking and retries — process","title":"Process batch of prompts with progress tracking and retries — process","text":"Process batch prompts progress tracking retries","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process batch of prompts with progress tracking and retries — process","text":"","code":"process(   chat_obj,   prompts,   type_spec = NULL,   state_path = tempfile(\"chat_\", fileext = \".rds\"),   echo = \"none\",   max_retries = 3L,   initial_delay = 1,   max_delay = 60,   backoff_factor = 2,   timeout = 60,   beep = TRUE )"},{"path":"https://dylanpieper.github.io/hellmer/reference/process.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process batch of prompts with progress tracking and retries — process","text":"chat_obj Chat model object prompts List prompts type_spec Type specification structured data state_path Path saving state echo Echo level (\"none\", \"text\", \"\") max_retries Maximum number retry attempts per prompt initial_delay Initial delay seconds first retry max_delay Maximum delay seconds retries backoff_factor Factor multiply delay retry timeout Maximum time seconds wait prompt response beep Play sound completion, interruption, error","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process batch of prompts with progress tracking and retries — process","text":"Batch results object","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_chunks.html","id":null,"dir":"Reference","previous_headings":"","what":"Process chunks of prompts in parallel — process_chunks","title":"Process chunks of prompts in parallel — process_chunks","text":"Process chunks prompts parallel","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_chunks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process chunks of prompts in parallel — process_chunks","text":"","code":"process_chunks(chunks, result, chat_obj, type_spec, pb, state_path, echo, beep)"},{"path":"https://dylanpieper.github.io/hellmer/reference/process_chunks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process chunks of prompts in parallel — process_chunks","text":"chunks List prompt chunks process result batch object store results chat_obj Chat model object making API calls type_spec Type specification structured data extraction pb Progress bar object state_path Path save intermediate state echo Level output display (\"none\", \"text\", \"\") beep Logical indicating whether play sounds","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_chunks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process chunks of prompts in parallel — process_chunks","text":"Updated batch object processed results","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_future.html","id":null,"dir":"Reference","previous_headings":"","what":"Process prompts in parallel chunks with error handling and state management — process_future","title":"Process prompts in parallel chunks with error handling and state management — process_future","text":"Process prompts parallel chunks error handling state management","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_future.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process prompts in parallel chunks with error handling and state management — process_future","text":"","code":"process_future(   chat_obj,   prompts,   type_spec = NULL,   state_path = tempfile(\"chat_\", fileext = \".rds\"),   workers = parallel::detectCores(),   chunk_size = NULL,   plan = \"multisession\",   max_chunk_attempts = 3L,   max_retries = 3L,   initial_delay = 1,   max_delay = 60,   backoff_factor = 2,   timeout = 60,   beep = TRUE )"},{"path":"https://dylanpieper.github.io/hellmer/reference/process_future.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process prompts in parallel chunks with error handling and state management — process_future","text":"chat_obj Chat model object API calls prompts Vector list prompts process type_spec Optional type specification structured data extraction state_path Path save intermediate state workers Number parallel workers (default: number CPU cores) chunk_size Number prompts process parallel time (default: 10% number prompts) plan Parallel backend: \"multisession\" \"multicore\" max_chunk_attempts Maximum retries per failed chunk (default: 3) max_retries Maximum retries per prompt (default: 3) initial_delay Initial delay first retry (default: 1) max_delay Maximum delay retries (default: 32) backoff_factor Delay multiplier retry (default: 2) timeout Maximum seconds per prompt (default: 60) beep Play sound completion/error (default: TRUE)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_future.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process prompts in parallel chunks with error handling and state management — process_future","text":"Batch results object containing processed responses","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract progress information from a batch — progress.batch","title":"Extract progress information from a batch — progress.batch","text":"Extract progress information batch","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract progress information from a batch — progress.batch","text":"x batch object","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract progress information from a batch — progress.batch","text":"list containing progress details","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.html","id":null,"dir":"Reference","previous_headings":"","what":"Get progress information from a batch result — progress","title":"Get progress information from a batch result — progress","text":"Get progress information batch result","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get progress information from a batch result — progress","text":"","code":"progress(x, ...)"},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get progress information from a batch result — progress","text":"x batch object ... Additional arguments passed methods","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get progress information from a batch result — progress","text":"list containing progress details","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get progress information from a batch result — progress","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create a chat processor chat <- chat_sequential(chat_openai())  # Process a batch of prompts batch <- chat$batch(list(   \"What is R?\",   \"Explain base R versus tidyverse\",   \"Explain vectors, lists, and data frames\" ))  # Check the progress batch$progress() }"},{"path":"https://dylanpieper.github.io/hellmer/reference/structured_data.batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract structured data from a batch — structured_data.batch","title":"Extract structured data from a batch — structured_data.batch","text":"Extract structured data batch","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/structured_data.batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract structured data from a batch — structured_data.batch","text":"x batch object","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/structured_data.batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract structured data from a batch — structured_data.batch","text":"List structured data","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/structured_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract structured data from a batch result — structured_data","title":"Extract structured data from a batch result — structured_data","text":"Extract structured data batch result","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/structured_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract structured data from a batch result — structured_data","text":"","code":"structured_data(x, ...)"},{"path":"https://dylanpieper.github.io/hellmer/reference/structured_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract structured data from a batch result — structured_data","text":"x batch object ... Additional arguments passed methods","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/structured_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract structured data from a batch result — structured_data","text":"list structured data objects","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/structured_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract structured data from a batch result — structured_data","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create a chat processor with type specification book_type <- type_object(   title = type_string(),   author = type_string(),   year = type_integer() )  # Create chat processor chat <- chat_sequential(chat_openai())  # Process a batch of prompts with type spec batch <- chat$batch(list(   \"Return info about 1984 by George Orwell\",   \"Return info about Brave New World by Aldous Huxley\" ), type_spec = book_type)  # Extract structured data batch$structured_data() }"},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract text responses from a batch — texts.batch","title":"Extract text responses from a batch — texts.batch","text":"Extract text responses batch","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract text responses from a batch — texts.batch","text":"x batch object flatten Logical; whether flatten structured data single string (default: TRUE)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract text responses from a batch — texts.batch","text":"character vector (original prompts supplied vector) list response texts (original prompts supplied list)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract texts from a batch result — texts","title":"Extract texts from a batch result — texts","text":"Extract texts batch result","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract texts from a batch result — texts","text":"","code":"texts(x, ...)"},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract texts from a batch result — texts","text":"x batch object ... Additional arguments passed methods","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract texts from a batch result — texts","text":"character vector list text responses","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract texts from a batch result — texts","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create a chat processor chat <- chat_sequential(chat_openai())  # Process a batch of prompts batch <- chat$batch(list(   \"What is R?\",   \"Explain base R versus tidyverse\",   \"Explain vectors, lists, and data frames\" ))  # Extract text responses batch$texts() }"},{"path":"https://dylanpieper.github.io/hellmer/news/index.html","id":"hellmer-010","dir":"Changelog","previous_headings":"","what":"hellmer 0.1.0","title":"hellmer 0.1.0","text":"Initial CRAN submission.","code":""}]
