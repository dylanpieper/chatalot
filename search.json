[{"path":"https://dylanpieper.github.io/hellmer/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 hellmer authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://dylanpieper.github.io/hellmer/articles/using-chat-models.html","id":"method-1-passing-an-object","dir":"Articles","previous_headings":"","what":"Method 1: Passing an Object","title":"Using Ellmer Chat Models","text":"first method pass chat model object. useful want reuse existing model configuration:","code":"library(hellmer)  openai <- chat_openai(   model = \"o3-mini\",   system_prompt = \"Reply concisely, one sentence\" )  chat <- chat_sequential(openai)"},{"path":"https://dylanpieper.github.io/hellmer/articles/using-chat-models.html","id":"method-2-passing-a-function","dir":"Articles","previous_headings":"","what":"Method 2: Passing a Function","title":"Using Ellmer Chat Models","text":"second method pass ellmer chat model function directly. method may preferred need use model aesthetically prefer nest functions. great reason use method, ’s available backward compatibility.","code":"chat <- chat_sequential(   chat_openai,   model = \"o3-mini\",   system_prompt = \"Reply concisely, one sentence\" )"},{"path":"https://dylanpieper.github.io/hellmer/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dylan Pieper. Author, maintainer.","code":""},{"path":"https://dylanpieper.github.io/hellmer/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Pieper D (2025). hellmer: Batch Processing Chat Models. R package version 0.1.2, https://dylanpieper.github.io/hellmer/.","code":"@Manual{,   title = {hellmer: Batch Processing for Chat Models},   author = {Dylan Pieper},   year = {2025},   note = {R package version 0.1.2},   url = {https://dylanpieper.github.io/hellmer/}, }"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"hellmer-","dir":"","previous_headings":"","what":"Batch Processing for Chat Models","title":"Batch Processing for Chat Models","text":"Enable sequential parallel processing chat models features supported ellmer, favoring speed feedback response streaming delayed responses batch APIs, cheaper slower supported LLM providers.","code":""},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"Batch Processing for Chat Models","text":"Process multiple chat interactions : Tooling structured data extraction Judgments structured data refinement Progress tracking recovery Automatic retry backoff Sound notifications","code":""},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Batch Processing for Chat Models","text":"can install package CRAN :","code":"install.packages(\"hellmer\")"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"setup-api-keys","dir":"","previous_headings":"","what":"Setup API Keys","title":"Batch Processing for Chat Models","text":"API keys allow access chat models stored environmental variables. recommend usethis package setup API keys .Renviron OPENAI_API_KEY=-key.","code":"usethis::edit_r_environ(scope = c(\"user\", \"project\"))"},{"path":[]},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"sequential-processing","dir":"","previous_headings":"Basic Usage","what":"Sequential Processing","title":"Batch Processing for Chat Models","text":"Sequential processing uses current R process call one chat time save data disk. Access batch results:","code":"library(hellmer)  chat <- chat_sequential(chat_openai(system_prompt = \"Reply concisely, one sentence\"))  prompts <- list(   \"What is R?\",   \"Explain base R versus tidyverse\" )  batch <- chat$batch(prompts) batch$progress() #> $total_prompts #> [1] 2 #>  #> $completed_prompts #> [1] 2 #>  #> $completion_percentage #> [1] 100 #>  #> $remaining_prompts #> [1] 0 #>  #> $state_path #> [1] \"/var/folders/.../chat_c5383b1279ae.rds\"  batch$texts() #> [[1]] #> [1] \"R is a programming language and software environment primarily used for  #> statistical computing and data analysis.\" #>  #> [[2]] #> [1] \"Base R refers to the R language's core packages and functionalities,  #> whereas Tidyverse is a collection of R packages designed for data science  #> that provides a more intuitive and consistent syntax.\"  batch$chats() #> [[1]] #> <Chat OpenAI/gpt-4o turns=3 tokens=22/18> #> ── system [0] ─────────────────────────────────────────────────────────────── #> Reply concisely, one sentence #> ── user [22] ──────────────────────────────────────────────────────────────── #> What is R? #> ── assistant [18] ─────────────────────────────────────────────────────────── #> R is a programming language and software environment primarily used for #> statistical computing and data analysis.  #> [[2]] #> <Chat OpenAI/gpt-4o turns=3 tokens=24/37> #> ── system [0] ─────────────────────────────────────────────────────────────── #> Reply concisely, one sentence #> ── user [24] ──────────────────────────────────────────────────────────────── #> Explain base R versus tidyverse #> ── assistant [37] ─────────────────────────────────────────────────────────── #> Base R refers to the R language's core packages and functionalities, whereas  #> Tidyverse is a collection of R packages designed for data science  #> that provides a more intuitive and consistent syntax."},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"parallel-processing","dir":"","previous_headings":"Basic Usage","what":"Parallel Processing","title":"Batch Processing for Chat Models","text":"Parallel processing spins multiple R processes, parallel workers, chat time. default, upper limit number workers = parallel::detectCores(), number prompts process time chunk_size = parallel::detectCores() * 5. chat chunk distributed across available R processes. chunk finished, data saved disk. maximum performance, set chunk_size number prompts (~4-5x faster). However, data saved disk chats processed.","code":"chat <- chat_future(chat_openai(system_prompt = \"Reply concisely, one sentence\")) batch <- chat$batch(   prompts,    chunk_size = length(prompts) )"},{"path":[]},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"tooling","dir":"","previous_headings":"Features","what":"Tooling","title":"Batch Processing for Chat Models","text":"Register use tools/function calling:","code":"get_current_time <- function(tz = \"UTC\") {   format(Sys.time(), tz = tz, usetz = TRUE) }  chat$register_tool(tool(   get_current_time,   \"Gets the current time in the given time zone.\",   tz = type_string(     \"The time zone to get the current time in. Defaults to `\\\"UTC\\\"`.\",     required = FALSE   ) ))  prompts <- list(   \"What time is it in Chicago?\",   \"What time is it in New York?\" )  batch <- chat$batch(prompts)  batch$texts() #> [[1]] #> [1] \"The current time in Chicago is 9:29 AM CDT.\" #>  #> [[2]] #> [1] \"The current time in New York is 10:29 AM EDT.\""},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"structured-data-extraction","dir":"","previous_headings":"Features","what":"Structured Data Extraction","title":"Batch Processing for Chat Models","text":"Extract structured data using type specifications: ask chat model evaluate refine structured data extractions, implement model-agnostic reasoning turns chat additional prompting using judgements parameter (increases token use):","code":"type_sentiment <- type_object(   \"Extract sentiment scores\",   positive_score = type_number(\"Positive sentiment score, 0.00 to 1.00\"),   negative_score = type_number(\"Negative sentiment score, 0.00 to 1.00\"),   neutral_score = type_number(\"Neutral sentiment score, 0.00 to 1.00\") )  prompts <- list(   \"The R community is really supportive and welcoming.\",   \"R has both base functions and tidyverse functions for data manipulation.\",   \"R's object-oriented system is confusing, inconsistent, and painful to use.\" )  batch <- chat$batch(prompts, type_spec = type_sentiment)  batch$texts() #> [[1]] #> $positive_score #> [1] 0.95 #>  #> $negative_score #> [1] 0.05 #>  #> $neutral_score #> [1] 0 #> ... batch <- chat$batch(prompts, type_spec = type_sentiment, judgements = 1)  batch$texts() #> [[1]] #> [[1]]$positive_score #> [1] 0.95 #>  #> [[1]]$negative_score #> [1] 0 #>  #> [[1]]$neutral_score #> [1] 0.05 #> ..."},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"progress-tracking-and-recovery","dir":"","previous_headings":"Features","what":"Progress Tracking and Recovery","title":"Batch Processing for Chat Models","text":"Batch processing state progress saved path .rds file disk allows resume interrupted operations: state_path defined, temporary file created default.","code":"batch <- chat$batch(prompts, state_path = \"chat_state.rds\") batch$progress()"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"automatic-retry","dir":"","previous_headings":"Features","what":"Automatic Retry","title":"Batch Processing for Chat Models","text":"Automatically retry failed requests exponential backoff, useful allow batch processing persist transient errors exceeding rate limits temporary server errors. chat provider functions ellmer retry least one time default, user-defined control retry strategy.","code":"batch <- chat$batch(   prompts = prompts,   # list or vector of prompts   max_retries = 3,     # maximum retry attempts   initial_delay = 20,  # initial delay in seconds   max_delay = 80,      # maximum delay between retries   backoff_factor = 2   # multiply delay by this factor after each retry )"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"sound-notifications","dir":"","previous_headings":"Features","what":"Sound Notifications","title":"Batch Processing for Chat Models","text":"Toggle sound notifications batch completion, interruption, error:","code":"chat <- chat_sequential(   chat_openai,   beep = TRUE )"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"echoing","dir":"","previous_headings":"Features","what":"Echoing","title":"Batch Processing for Chat Models","text":"default, chat echo set FALSE show progress bar. However, can still configure echo $batch call first setting progress FALSE:","code":"batch <- chat$batch(prompts, progress = FALSE, echo = \"all\") #> > What is R? #> < R is a programming language and software environment used for statistical computing, #> < data analysis, and graphical representation. #> <  #> > Explain base R versus tidyverse #> < Base R refers to the functions and paradigms built into the R language, while #> < tidyverse is a collection of R packages designed for data science, emphasizing  #> < a more consistent and human-readable syntax for data manipulation. #> <"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"methods","dir":"","previous_headings":"Features","what":"Methods","title":"Batch Processing for Chat Models","text":"progress(): Returns processing status texts(): Returns response texts format input prompts (.e., list prompts provided list, character vector prompts provided vector). type specification provided, returns structured data instead plain text. chats(): Returns list chat objects","code":""},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"further-reading","dir":"","previous_headings":"","what":"Further Reading","title":"Batch Processing for Chat Models","text":"Using Ellmer Chat Models","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.future_chat.html","id":null,"dir":"Reference","previous_headings":"","what":"Process a batch of prompts with a parallel chat — batch.future_chat","title":"Process a batch of prompts with a parallel chat — batch.future_chat","text":"Process batch prompts parallel chat","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.future_chat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process a batch of prompts with a parallel chat — batch.future_chat","text":"","code":"batch.future_chat(   chat_env,   prompts,   type_spec = NULL,   judgements = 0,   state_path = tempfile(\"chat_\", fileext = \".rds\"),   workers = NULL,   chunk_size = parallel::detectCores() * 5,   plan = \"multisession\",   max_chunk_attempts = 3L,   max_retries = 3L,   initial_delay = 20,   max_delay = 80,   backoff_factor = 2,   beep = TRUE,   progress = TRUE,   echo = FALSE,   ... )"},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.future_chat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process a batch of prompts with a parallel chat — batch.future_chat","text":"chat_env chat environment chat_future prompts List prompts process type_spec Type specification structured data extraction judgements Number judgements structured data extraction resulting refined data state_path Path save state file workers Number parallel workers chunk_size Number prompts worker processes time plan Parallel backend (\"multisession\" \"multicore\") max_chunk_attempts Maximum retries per failed chunk max_retries Maximum number retry attempts failed requests initial_delay Initial delay first retry seconds max_delay Maximum delay retries seconds backoff_factor Factor multiply delay retry beep Whether play sound completion progress Whether show progress bars echo Whether display chat outputs (progress FALSE) ... Additional arguments passed chat method","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.future_chat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process a batch of prompts with a parallel chat — batch.future_chat","text":"batch object processed results","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Batch result class for managing chat processing results — batch","title":"Batch result class for managing chat processing results — batch","text":"Batch result class managing chat processing results","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Batch result class for managing chat processing results — batch","text":"","code":"batch(   prompts = list(),   responses = list(),   completed = integer(0),   state_path = character(0),   type_spec = NULL,   judgements = integer(0),   progress = logical(0),   input_type = character(0),   max_retries = integer(0),   initial_delay = integer(0),   max_delay = integer(0),   backoff_factor = integer(0),   chunk_size = integer(0),   workers = integer(0),   plan = character(0),   beep = logical(0),   echo = logical(0),   state = list() )"},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Batch result class for managing chat processing results — batch","text":"prompts List prompts process responses List store responses completed Integer indicating number completed prompts state_path Path save state file type_spec Type specification structured data extraction judgements Number judgements batch_judge() workflow (1 = initial extract + 1 judgement, 2 = initial extract + 2 judgements, etc.) progress Whether show progress bars (default: TRUE) input_type Type input (\"vector\" \"list\") max_retries Maximum number retry attempts initial_delay Initial delay first retry max_delay Maximum delay retries backoff_factor Factor multiply delay retry chunk_size Size chunks parallel processing workers Number parallel workers plan Parallel backend plan beep Play sound completion (default: TRUE) echo Whether echo messages processing (default: FALSE) state Internal state tracking","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Batch result class for managing chat processing results — batch","text":"Returns S7 class object class \"batch\" represents collection prompts responses chat models. object contains input parameters properties provides methods : Extracting text responses via texts() (includes structured data type specification provided) Accessing full chat objects via chats() Tracking processing progress via progress() batch object manages prompt processing, tracks completion status, handles retries failed requests.","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Batch result class for managing chat processing results — batch","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create a chat processor chat <- chat_sequential(chat_openai())  # Process a batch of prompts batch <- chat$batch(list(   \"What is R?\",   \"Explain base R versus tidyverse\",   \"Explain vectors, lists, and data frames\" ))  # Check the progress if interrupted batch$progress()  # Return the responses as a vector or list batch$texts()  # Return the chat objects batch$chats() }"},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.sequential_chat.html","id":null,"dir":"Reference","previous_headings":"","what":"Process a batch of prompts with a sequential chat — batch.sequential_chat","title":"Process a batch of prompts with a sequential chat — batch.sequential_chat","text":"Process batch prompts sequential chat","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.sequential_chat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process a batch of prompts with a sequential chat — batch.sequential_chat","text":"","code":"batch.sequential_chat(   chat_env,   prompts,   type_spec = NULL,   judgements = 0,   state_path = tempfile(\"chat_\", fileext = \".rds\"),   progress = TRUE,   max_retries = 3L,   initial_delay = 20,   max_delay = 80,   backoff_factor = 2,   beep = TRUE,   echo = FALSE,   ... )"},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.sequential_chat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process a batch of prompts with a sequential chat — batch.sequential_chat","text":"chat_env chat environment chat_sequential prompts List prompts process type_spec Type specification structured data extraction judgements Number judgements (1 = initial extract + 1 judgement, 2 = initial extract + 2 judgements, etc.) state_path Path save state file progress Whether show progress bars max_retries Maximum number retry attempts failed requests initial_delay Initial delay first retry seconds max_delay Maximum delay retries seconds backoff_factor Factor multiply delay retry beep Whether play sound completion echo Whether display chat outputs (progress FALSE) ... Additional arguments passed chat method","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.sequential_chat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process a batch of prompts with a sequential chat — batch.sequential_chat","text":"batch object processed results","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/capture.html","id":null,"dir":"Reference","previous_headings":"","what":"Capture chat model response with proper handling — capture","title":"Capture chat model response with proper handling — capture","text":"Capture chat model response proper handling","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/capture.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Capture chat model response with proper handling — capture","text":"","code":"capture(original_chat, prompt, type_spec, judgements, echo, ...)"},{"path":"https://dylanpieper.github.io/hellmer/reference/capture.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Capture chat model response with proper handling — capture","text":"original_chat Original chat model object prompt Prompt text type_spec Type specification structured data judgements Number judgements structured data extraction resulting refined data","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/capture.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Capture chat model response with proper handling — capture","text":"List containing response information","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/capture_with_retry.html","id":null,"dir":"Reference","previous_headings":"","what":"Capture chat model response with proper handling and retries — capture_with_retry","title":"Capture chat model response with proper handling and retries — capture_with_retry","text":"Capture chat model response proper handling retries","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/capture_with_retry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Capture chat model response with proper handling and retries — capture_with_retry","text":"","code":"capture_with_retry(   original_chat,   prompt,   type_spec,   judgements,   max_retries,   initial_delay,   max_delay,   backoff_factor,   echo,   ... )"},{"path":"https://dylanpieper.github.io/hellmer/reference/capture_with_retry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Capture chat model response with proper handling and retries — capture_with_retry","text":"original_chat Original chat model object prompt Prompt text type_spec Type specification structured data judgements Number judgements structured data extraction resulting refined data max_retries Maximum number retry attempts initial_delay Initial delay seconds first retry max_delay Maximum delay seconds retries backoff_factor Factor multiply delay retry","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/capture_with_retry.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Capture chat model response with proper handling and retries — capture_with_retry","text":"List containing response information","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_future.html","id":null,"dir":"Reference","previous_headings":"","what":"Process a batch of prompts in parallel — chat_future","title":"Process a batch of prompts in parallel — chat_future","text":"Processes batch chat prompts using parallel workers. Splits prompts chunks processing maintaining state. sequential processing, use chat_sequential().","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_future.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process a batch of prompts in parallel — chat_future","text":"","code":"chat_future(chat_model = NULL, ...)"},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_future.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process a batch of prompts in parallel — chat_future","text":"chat_model ellmer chat model object function (e.g., chat_openai()) ... Additional arguments passed underlying chat model (e.g., system_prompt)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_future.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process a batch of prompts in parallel — chat_future","text":"batch object (S7 class) containing: prompts: Original input prompts responses: Raw response data completed prompts completed: Number successfully processed prompts state_path: Path batch state saved type_spec: Type specification used structured data texts: Function extract text responses structured data chats: Function extract chat objects progress: Function get processing status batch: Function process batch prompts","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_future.html","id":"batch-method","dir":"Reference","previous_headings":"","what":"Batch Method","title":"Process a batch of prompts in parallel — chat_future","text":"function provides access batch() method parallel processing prompts. See ?batch.future_chat full details method parameters.","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_future.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process a batch of prompts in parallel — chat_future","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create a parallel chat processor with an object chat <- chat_future(chat_openai(system_prompt = \"Reply concisely\"))  # Or a function chat <- chat_future(chat_openai, system_prompt = \"Reply concisely, one sentence\")  # Process a batch of prompts in parallel batch <- chat$batch(   list(     \"What is R?\",     \"Explain base R versus tidyverse\",     \"Explain vectors, lists, and data frames\"   ),   chunk_size = 3 )  # Process batch with echo enabled (when progress is disabled) batch <- chat$batch(   list(     \"What is R?\",     \"Explain base R versus tidyverse\"   ),   progress = FALSE,   echo = TRUE )  # Check the progress if interrupted batch$progress()  # Return the responses batch$texts()  # Return the chat objects batch$chats() }"},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_sequential.html","id":null,"dir":"Reference","previous_headings":"","what":"Process a batch of prompts in sequence — chat_sequential","title":"Process a batch of prompts in sequence — chat_sequential","text":"Processes batch chat prompts one time sequential order. Maintains state runs can resume interrupted processing. parallel processing, use chat_future().","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_sequential.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process a batch of prompts in sequence — chat_sequential","text":"","code":"chat_sequential(chat_model = NULL, ...)"},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_sequential.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process a batch of prompts in sequence — chat_sequential","text":"chat_model ellmer chat model object function (e.g., chat_openai()) ... Additional arguments passed underlying chat model (e.g., system_prompt)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_sequential.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process a batch of prompts in sequence — chat_sequential","text":"batch object (S7 class) containing prompts: Original input prompts responses: Raw response data completed prompts completed: Number successfully processed prompts state_path: Path batch state saved type_spec: Type specification used structured data texts: Function extract text responses structured data chats: Function extract chat objects progress: Function get processing status batch: Function process batch prompts","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_sequential.html","id":"batch-method","dir":"Reference","previous_headings":"","what":"Batch Method","title":"Process a batch of prompts in sequence — chat_sequential","text":"function provides access batch() method sequential processing prompts. See ?batch.sequential_chat full details method parameters.","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_sequential.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process a batch of prompts in sequence — chat_sequential","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create a sequential chat processor with an object chat <- chat_sequential(chat_openai(system_prompt = \"Reply concisely\"))  # Or a function chat <- chat_sequential(chat_openai, system_prompt = \"Reply concisely, one sentence\")  # Process a batch of prompts in sequence batch <- chat$batch(   list(     \"What is R?\",     \"Explain base R versus tidyverse\",     \"Explain vectors, lists, and data frames\"   ),   max_retries = 3L,   initial_delay = 20,   beep = TRUE )  # Process batch with echo enabled (when progress is disabled) batch <- chat$batch(   list(     \"What is R?\",     \"Explain base R versus tidyverse\"   ),   progress = FALSE,   echo = TRUE )  # Check the progress if interrupted batch$progress()  # Return the responses batch$texts()  # Return the chat objects batch$chats() }"},{"path":"https://dylanpieper.github.io/hellmer/reference/chats.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract chat objects from a batch result — chats","title":"Extract chat objects from a batch result — chats","text":"Extract chat objects batch result","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract chat objects from a batch result — chats","text":"","code":"chats(x, ...)"},{"path":"https://dylanpieper.github.io/hellmer/reference/chats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract chat objects from a batch result — chats","text":"x batch object ... Additional arguments","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract chat objects from a batch result — chats","text":"list chat objects","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chats.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract chat objects from a batch result — chats","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create a chat processor chat <- chat_sequential(chat_openai())  # Process a batch of prompts batch <- chat$batch(list(   \"What is R?\",   \"Explain base R versus tidyverse\",   \"Explain vectors, lists, and data frames\" ))  # Return the chat objects batch$chats() }"},{"path":"https://dylanpieper.github.io/hellmer/reference/create_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Create results object from batch — create_results","title":"Create results object from batch — create_results","text":"Create results object batch","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/create_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create results object from batch — create_results","text":"","code":"create_results(result)"},{"path":"https://dylanpieper.github.io/hellmer/reference/create_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create results object from batch — create_results","text":"result Batch object","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/create_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create results object from batch — create_results","text":"Results object class \"batch\"","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/finish_successful_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Finish successful batch processing — finish_successful_batch","title":"Finish successful batch processing — finish_successful_batch","text":"Called successful completion batch processing update progress indicators provide feedback","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/finish_successful_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finish successful batch processing — finish_successful_batch","text":"","code":"finish_successful_batch(pb, beep)"},{"path":"https://dylanpieper.github.io/hellmer/reference/finish_successful_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finish successful batch processing — finish_successful_batch","text":"pb Progress bar object beep Logical; whether play success sound","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/finish_successful_batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Finish successful batch processing — finish_successful_batch","text":"NULL (invisibly)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/handle_batch_interrupt.html","id":null,"dir":"Reference","previous_headings":"","what":"Handle batch interruption — handle_batch_interrupt","title":"Handle batch interruption — handle_batch_interrupt","text":"Handle batch interruption","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/handle_batch_interrupt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Handle batch interruption — handle_batch_interrupt","text":"","code":"handle_batch_interrupt(result, beep)"},{"path":"https://dylanpieper.github.io/hellmer/reference/handle_batch_interrupt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Handle batch interruption — handle_batch_interrupt","text":"result batch object containing processing state beep Logical indicating whether play sound","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/handle_batch_interrupt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Handle batch interruption — handle_batch_interrupt","text":"NULL (called side effects)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/hellmer-package.html","id":null,"dir":"Reference","previous_headings":"","what":"hellmer: Batch Processing for Chat Models — hellmer-package","title":"hellmer: Batch Processing for Chat Models — hellmer-package","text":"Batch processing framework 'ellmer' chat models. Provides sequential parallel processing chat interactions features including tool calling structured data extraction. Enables workflow management progress tracking recovery, automatic retry backoff. Additional quality--life features include verbosity control sound notifications. Parallel processing implemented via 'future' framework. Includes methods retrieving progress status, chat texts, chat objects.","code":""},{"path":[]},{"path":"https://dylanpieper.github.io/hellmer/reference/hellmer-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"hellmer: Batch Processing for Chat Models — hellmer-package","text":"Maintainer: Dylan Pieper dylanpieper@gmail.com","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/is_retry_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if an error is eligible for retry — is_retry_error","title":"Check if an error is eligible for retry — is_retry_error","text":"Check error eligible retry","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/is_retry_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if an error is eligible for retry — is_retry_error","text":"","code":"is_retry_error(error)"},{"path":"https://dylanpieper.github.io/hellmer/reference/is_retry_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if an error is eligible for retry — is_retry_error","text":"error error object","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/is_retry_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if an error is eligible for retry — is_retry_error","text":"TRUE eligible retry, FALSE otherwise","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_chunks.html","id":null,"dir":"Reference","previous_headings":"","what":"Process chunks of prompts in parallel — process_chunks","title":"Process chunks of prompts in parallel — process_chunks","text":"Process chunks prompts parallel","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_chunks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process chunks of prompts in parallel — process_chunks","text":"","code":"process_chunks(   chunks,   result,   chat_obj,   type_spec,   judgements,   pb,   state_path,   progress,   beep,   max_retries,   initial_delay,   max_delay,   backoff_factor,   echo,   ... )"},{"path":"https://dylanpieper.github.io/hellmer/reference/process_chunks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process chunks of prompts in parallel — process_chunks","text":"chunks List prompt chunks process result batch object store results chat_obj Chat model object making API calls type_spec Type specification structured data extraction judgements Number judgements structured data extraction resulting refined data pb Progress bar object state_path Path save intermediate state progress Whether show progress bars beep Logical indicating whether play sounds max_retries Maximum number retry attempts initial_delay Initial delay seconds first retry max_delay Maximum delay seconds retries backoff_factor Factor multiply delay retry","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_chunks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process chunks of prompts in parallel — process_chunks","text":"Updated batch object processed results","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_future.html","id":null,"dir":"Reference","previous_headings":"","what":"Process prompts in parallel chunks with error handling and state management — process_future","title":"Process prompts in parallel chunks with error handling and state management — process_future","text":"Process prompts parallel chunks error handling state management","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_future.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process prompts in parallel chunks with error handling and state management — process_future","text":"","code":"process_future(   chat_obj,   prompts,   type_spec,   judgements,   state_path,   workers,   chunk_size,   plan,   max_chunk_attempts,   max_retries,   initial_delay,   max_delay,   backoff_factor,   beep,   progress,   echo,   ... )"},{"path":"https://dylanpieper.github.io/hellmer/reference/process_future.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process prompts in parallel chunks with error handling and state management — process_future","text":"chat_obj Chat model object API calls prompts Vector list prompts process type_spec Optional type specification structured data extraction judgements Number judgements structured data extraction resulting refined data state_path Path save intermediate state workers Number parallel workers chunk_size Number prompts process parallel time plan Parallel backend max_chunk_attempts Maximum retries per failed chunk max_retries Maximum retries per prompt initial_delay Initial delay first retry max_delay Maximum delay retries backoff_factor Delay multiplier retry beep Play sound completion/error progress Whether show progress bars","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_future.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process prompts in parallel chunks with error handling and state management — process_future","text":"Batch results object","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_judgements.html","id":null,"dir":"Reference","previous_headings":"","what":"Process structured data extraction with judgement — process_judgements","title":"Process structured data extraction with judgement — process_judgements","text":"Process structured data extraction judgement","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_judgements.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process structured data extraction with judgement — process_judgements","text":"","code":"process_judgements(   chat_obj,   prompt,   type_spec,   judgements = 0,   echo = FALSE,   ... )"},{"path":"https://dylanpieper.github.io/hellmer/reference/process_judgements.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process structured data extraction with judgement — process_judgements","text":"chat_obj Chat model object prompt prompt text analyze type_spec Type specification structured data judgements Number judgements structured data extraction resulting refined data","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_judgements.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process structured data extraction with judgement — process_judgements","text":"List containing extraction process","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_sequential.html","id":null,"dir":"Reference","previous_headings":"","what":"Process batch of prompts with progress tracking and retries — process_sequential","title":"Process batch of prompts with progress tracking and retries — process_sequential","text":"Process batch prompts progress tracking retries","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_sequential.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process batch of prompts with progress tracking and retries — process_sequential","text":"","code":"process_sequential(   chat_obj,   prompts,   type_spec,   judgements,   state_path,   progress,   max_retries,   initial_delay,   max_delay,   backoff_factor,   beep,   echo,   ... )"},{"path":"https://dylanpieper.github.io/hellmer/reference/process_sequential.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process batch of prompts with progress tracking and retries — process_sequential","text":"chat_obj Chat model object prompts List prompts type_spec Type specification structured data judgements Number judgements structured data extraction resulting refined data state_path Path saving state progress Whether show progress bars max_retries Maximum retry attempts initial_delay Initial delay retry max_delay Maximum delay retries backoff_factor Factor multiply delay beep Play sound completion","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_sequential.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process batch of prompts with progress tracking and retries — process_sequential","text":"Batch results object","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.html","id":null,"dir":"Reference","previous_headings":"","what":"Get progress information from a batch result — progress","title":"Get progress information from a batch result — progress","text":"Get progress information batch result","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get progress information from a batch result — progress","text":"","code":"progress(x, ...)"},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get progress information from a batch result — progress","text":"x batch object ... Additional arguments passed methods","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get progress information from a batch result — progress","text":"list containing progress details","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get progress information from a batch result — progress","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create a chat processor chat <- chat_sequential(chat_openai())  # Process a batch of prompts batch <- chat$batch(list(   \"What is R?\",   \"Explain base R versus tidyverse\",   \"Explain vectors, lists, and data frames\" ))  # Check the progress batch$progress() }"},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract texts or structured data from a batch result — texts","title":"Extract texts or structured data from a batch result — texts","text":"Extract texts structured data batch result","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract texts or structured data from a batch result — texts","text":"","code":"texts(x, ...)"},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract texts or structured data from a batch result — texts","text":"x batch object ... Additional arguments passed methods","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract texts or structured data from a batch result — texts","text":"character vector list text responses. type specification provided batch, structured data objects returned instead.","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract texts or structured data from a batch result — texts","text":"","code":"if (FALSE) { # ellmer::has_credentials(\"openai\") # Create a chat processor chat <- chat_sequential(chat_openai())  # Process a batch of prompts batch <- chat$batch(list(   \"What is R?\",   \"Explain base R versus tidyverse\",   \"Explain vectors, lists, and data frames\" ))  # Extract text responses batch$texts() }"},{"path":[]},{"path":"https://dylanpieper.github.io/hellmer/news/index.html","id":"new-features-0-1-2","dir":"Changelog","previous_headings":"","what":"New Features","title":"hellmer 0.1.2","text":"chat_future() now uses uses CPU cores * 5 default chunk size $batch() gains progress addition echo ... passed chat call","code":""},{"path":"https://dylanpieper.github.io/hellmer/news/index.html","id":"lifecycle-changes-0-1-2","dir":"Changelog","previous_headings":"","what":"Lifecycle changes","title":"hellmer 0.1.2","text":"Removed timeout feature ’s better handled option(ellmer_timeout_s = 120) ellmer 0.1.1 Moved parameters chat_sequential() chat_future() $batch() except chat_model ...","code":""},{"path":"https://dylanpieper.github.io/hellmer/news/index.html","id":"hellmer-011","dir":"Changelog","previous_headings":"","what":"hellmer 0.1.1","title":"hellmer 0.1.1","text":"CRAN release: 2025-03-14","code":""},{"path":"https://dylanpieper.github.io/hellmer/news/index.html","id":"new-features-0-1-1","dir":"Changelog","previous_headings":"","what":"New features","title":"hellmer 0.1.1","text":"Removed structured_data() method texts() now handles structured data responses Updated package documentation better organization clarity","code":""},{"path":"https://dylanpieper.github.io/hellmer/news/index.html","id":"experimental-features-0-1-1","dir":"Changelog","previous_headings":"","what":"Experimental features","title":"hellmer 0.1.1","text":"Structured data extractions support judgements refine extracted data via judgements parameter","code":""},{"path":"https://dylanpieper.github.io/hellmer/news/index.html","id":"hellmer-010","dir":"Changelog","previous_headings":"","what":"hellmer 0.1.0","title":"hellmer 0.1.0","text":"CRAN release: 2025-03-07","code":""},{"path":"https://dylanpieper.github.io/hellmer/news/index.html","id":"new-features-0-1-0","dir":"Changelog","previous_headings":"","what":"New features","title":"hellmer 0.1.0","text":"Initial CRAN submission","code":""}]
