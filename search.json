[{"path":"https://dylanpieper.github.io/hellmer/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 hellmer authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://dylanpieper.github.io/hellmer/articles/comparing-packages.html","id":"overview","dir":"Articles","previous_headings":"","what":"Overview","title":"Comparing Packages for Batching LLM Tasks","text":"vignette compares different approaches batching LLM operations R. two main packages provide batch processing capabilities : hellmer: Synchronous batch processing models supported ellmer tidyllm: Synchronous asynchronous batch processing wide range models","code":""},{"path":[]},{"path":"https://dylanpieper.github.io/hellmer/articles/comparing-packages.html","id":"hellmer","dir":"Articles","previous_headings":"Package Comparison","what":"hellmer","title":"Comparing Packages for Batching LLM Tasks","text":"Focuses synchronous batch processing robust features: Key features: Ellmer’s tooling structured data extraction State persistence recovery Progress tracking Configurable output verbosity Automatic retry backoff Timeout handling Sound notifications","code":"library(hellmer)  chat <- chat_sequential(chat_claude, system_prompt = \"Reply concisely\") result <- chat$batch(list(\"What is 2+2?\",                          \"Name one planet.\",                          \"Is water wet?\",                          \"What color is the sky?\"))  result$progress() result$texts() result$chats()"},{"path":"https://dylanpieper.github.io/hellmer/articles/comparing-packages.html","id":"tidyllm","dir":"Articles","previous_headings":"Package Comparison","what":"tidyllm","title":"Comparing Packages for Batching LLM Tasks","text":"Supports synchronous asynchronous batch processing basic features side-effect-free, pipeline-oriented user interface: Key features: synchronous asynchronous processing options Asynchronous processing supports Anthropic, OpenAI, Mistral, Ollama APIs Efficient parallel request queuing Ollama Status checking capabilities async jobs Cost savings (~50% cheaper async) Limitations synchronous batching: progress feedback processing state management recovery Returns simple chat objects methods automatic retry error handling timeout management","code":"library(tidyllm)  # Basic asynchronous batching glue(\"Write a response to: {x}\",       x = c(        \"What is 2+2?\",        \"Name one planet.\",        \"Is water wet?\",        \"What color is the sky?\"      )) |>   purrr::map(llm_message) |>   send_batch(claude()) |>   saveRDS(\"claude_batch.rds\")  readRDS(\"claude_batch.rds\") |>   check_batch(claude())  # Synchronous batching conversations <- c(   \"What is 2+2?\",   \"Name one planet.\",   \"Is water wet?\",   \"What color is the sky?\" ) |>   purrr::map(~ {     llm_message(.x) |>       chat(claude())   })"},{"path":"https://dylanpieper.github.io/hellmer/articles/comparing-packages.html","id":"benchmark","dir":"Articles","previous_headings":"","what":"Benchmark","title":"Comparing Packages for Batching LLM Tasks","text":"comparing performance two packages methods (n = 10), hellmer’s parallel processing best performance.","code":""},{"path":"https://dylanpieper.github.io/hellmer/articles/comparing-packages.html","id":"honorable-mentions","dir":"Articles","previous_headings":"","what":"Honorable Mentions","title":"Comparing Packages for Batching LLM Tasks","text":"packages provide batch processing capabilities Ollama models:","code":""},{"path":"https://dylanpieper.github.io/hellmer/articles/comparing-packages.html","id":"mall","dir":"Articles","previous_headings":"Honorable Mentions","what":"mall","title":"Comparing Packages for Batching LLM Tasks","text":"mall provides synchronous batching local Ollama models features like row-wise dataframe processing, integrated caching, pre-built NLP task prompts.","code":""},{"path":"https://dylanpieper.github.io/hellmer/articles/comparing-packages.html","id":"rollama","dir":"Articles","previous_headings":"Honorable Mentions","what":"rollama","title":"Comparing Packages for Batching LLM Tasks","text":"rollama specializes efficient batch processing Ollama models, particularly structured tasks like zero-shot classification.","code":""},{"path":"https://dylanpieper.github.io/hellmer/articles/comparing-packages.html","id":"when-to-use-each-package","dir":"Articles","previous_headings":"","what":"When to Use Each Package","title":"Comparing Packages for Batching LLM Tasks","text":"Use hellmer production-grade batch processing, especially large batches sensitive tasks Cost-effective async processing Simple synchronous batching","code":""},{"path":"https://dylanpieper.github.io/hellmer/articles/comparing-packages.html","id":"performance-considerations","dir":"Articles","previous_headings":"","what":"Performance Considerations","title":"Comparing Packages for Batching LLM Tasks","text":"Better immediate feedback structured tasks Blocks R completion Consumes local resources Provides robust error handling state management Better long-running jobs cost savings Requires status checking block R Outsources batching compute Limited error handling state management choice approaches depends specific needs error handling, state management, execution environment. production workflows requiring robust error handling state management, hellmer provides best solution. simple batching needs async processing preferred, tidyllm offers flexible alternative.","code":""},{"path":"https://dylanpieper.github.io/hellmer/articles/using-chat-models.html","id":"method-1-passing-a-function","dir":"Articles","previous_headings":"","what":"Method 1: Passing a Function","title":"Using Ellmer Chat Models","text":"first method pass ellmer chat model function directly. preferred method lets hellmer setup model, specifically setting echo = \"none\" cleaner console output: case, hellmer : Recognize chat_model function Setup model echo = \"none\" additional parameters provide Use newly created model batch processing","code":"library(hellmer)  # Sequential processing chat <- chat_sequential(   chat_model = chat_claude,   system_prompt = \"Reply concisely\" )  # Parallel processing chat <- chat_future(   chat_model = chat_claude,   system_prompt = \"Reply concisely\",   workers = 4 )"},{"path":"https://dylanpieper.github.io/hellmer/articles/using-chat-models.html","id":"method-2-passing-an-object","dir":"Articles","previous_headings":"","what":"Method 2: Passing an Object","title":"Using Ellmer Chat Models","text":"second method pass chat model object. useful need control model configuration want reuse existing model: case, hellmer : Recognize chat_model object Use model -existing configuration","code":"library(hellmer)  # Create and configure a chat model claude <- chat_claude(   system_prompt = \"Reply concisely\",   echo = \"none\",   max_tokens = 1000 )  # Sequential processing chat <- chat_sequential(chat_model = claude)  # Parallel processing chat <- chat_future(   chat_model = claude,   workers = 4 )"},{"path":"https://dylanpieper.github.io/hellmer/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Dylan Pieper. Author, maintainer.","code":""},{"path":"https://dylanpieper.github.io/hellmer/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Pieper D (2025). hellmer: Batch Processing Chat Models. R package version 0.1.0, https://dylanpieper.github.io/hellmer/.","code":"@Manual{,   title = {hellmer: Batch Processing for Chat Models},   author = {Dylan Pieper},   year = {2025},   note = {R package version 0.1.0},   url = {https://dylanpieper.github.io/hellmer/}, }"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"hellmer-","dir":"","previous_headings":"","what":"Batch Processing for Chat Models","title":"Batch Processing for Chat Models","text":"package enables sequential parallel batch processing chat models ellmer.","code":""},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Batch Processing for Chat Models","text":"Process multiple chat interactions : Ellmer’s tooling structured data extraction State persistence recovery Progress tracking Configurable output verbosity Automatic retry backoff Timeout handling Sound notifications","code":""},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Batch Processing for Chat Models","text":"","code":"devtools::install_github(\"dylanpieper/hellmer\")"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"load-package","dir":"","previous_headings":"","what":"Load Package","title":"Batch Processing for Chat Models","text":"Run library(hellmer) get started. package attaches ellmer easy access chat models.","code":""},{"path":[]},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"sequential-processing","dir":"","previous_headings":"Basic Usage","what":"Sequential Processing","title":"Batch Processing for Chat Models","text":"","code":"chat <- chat_sequential(chat_claude, system_prompt = \"Reply concisely\")  prompts <- list(   \"What is 2+2?\",   \"Name one planet.\",   \"Is water wet?\",   \"What color is the sky?\",   \"Count to 3.\",   \"Say hello.\",   \"Name a primary color.\",   \"What is 5x5?\",   \"True or false: Birds can fly.\",   \"What day comes after Monday?\" )  result <- chat$batch(prompts)  result$progress() result$texts() result$chats()"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"parallel-processing","dir":"","previous_headings":"Basic Usage","what":"Parallel Processing","title":"Batch Processing for Chat Models","text":"Simply swap chat_sequential() chat_future() enable parallel processing.","code":"chat <- chat_future(chat_claude, system_prompt = \"Reply concisely\")"},{"path":[]},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"tooling","dir":"","previous_headings":"Features","what":"Tooling","title":"Batch Processing for Chat Models","text":"Register use tools/function calling:","code":"square_number <- function(num) num^2  chat$register_tool(tool(   square_number,   \"Calculates the square of a given number\",   num = type_integer(\"The number to square\") ))  prompts <- list(   \"What is the square of 3?\",   \"Calculate the square of 5.\" )"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"structured-data-extraction","dir":"","previous_headings":"Features","what":"Structured Data Extraction","title":"Batch Processing for Chat Models","text":"Extract structured data using type specifications:","code":"type_sentiment <- type_object(   \"Extract sentiment scores\",   positive_score = type_number(\"Positive sentiment score, 0.0 to 1.0\"),   negative_score = type_number(\"Negative sentiment score, 0.0 to 1.0\"),   neutral_score = type_number(\"Neutral sentiment score, 0.0 to 1.0\") )  prompts <- list(   \"I love this product! It's amazing!\",   \"This is okay, nothing special.\",   \"Terrible experience, very disappointed.\" )  result <- chat$batch(prompts, type_spec = type_sentiment) structured_data <- result$structured_data()"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"state-management","dir":"","previous_headings":"Features","what":"State Management","title":"Batch Processing for Chat Models","text":"Batch processing automatically saves state can resume interrupted operations: state_path defined, temporary file created default.","code":"result <- chat$batch(prompts, state_path = \"chat_state.rds\")"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"output-control","dir":"","previous_headings":"Features","what":"Output Control","title":"Batch Processing for Chat Models","text":"Control verbosity echo parameter (sequential ): \"none\": Silent operation progress bar \"text\": Show chat responses \"\": Show prompts responses","code":"chat <- chat_sequential(   chat_claude,    echo = \"none\" )"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"automatic-retry","dir":"","previous_headings":"Features","what":"Automatic Retry","title":"Batch Processing for Chat Models","text":"Automatically retry failed requests backoff, serves wide guardrail token/RPM limits random errors: request fails, code : Wait initial_delay Retry request fails , wait (delay × backoff_factor) Continue success max_retries reached code detects authorization API key issue, stop immediately.","code":"chat <- chat_sequential(   chat_claude,         # Base chat model   max_retries = 3,     # Maximum number of retry attempts   initial_delay = 20,  # Initial delay in seconds   max_delay = 60,      # Maximum delay between retries   backoff_factor = 2   # Multiply delay by this factor after each retry )"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"timeout-handling","dir":"","previous_headings":"Features","what":"Timeout Handling","title":"Batch Processing for Chat Models","text":"timeout parameter specifies maximum time wait response chat model prompt. However, parameter still limited timeouts propagated chat models.","code":"chat <- chat_future(   chat_ollama,   model = \"deepseek-r1:8b\",   system_prompt = \"Reply in one sentence or less\",   timeout = 60 )"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"sound-notifications","dir":"","previous_headings":"Features","what":"Sound Notifications","title":"Batch Processing for Chat Models","text":"Toggle sound notifications batch completion, interruption, error:","code":"chat <- chat_sequential(   chat_claude,   beep = TRUE )"},{"path":[]},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"chat_sequential","dir":"","previous_headings":"Quick References","what":"chat_sequential()","title":"Batch Processing for Chat Models","text":"Creates sequential batch processor.","code":"chat_sequential(   chat_model = chat_claude,  # Ellmer chat model   echo = \"none\",             # Output verbosity (sequential only)   beep = TRUE,               # Toggle sound notifications   max_retries = 3,           # Maximum retry attempts   initial_delay = 20,        # Initial retry delay in seconds   max_delay = 60,            # Maximum delay between retries   backoff_factor = 2,        # Retry backoff multiplier   timeout = 60,              # Maximum seconds to wait for response   ...                        # Pass parameters to the chat model )"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"chat_future","dir":"","previous_headings":"Quick References","what":"chat_future()","title":"Batch Processing for Chat Models","text":"Creates parallel batch processor.","code":"chat_future(   chat_model = chat_claude,  # Ellmer chat model   workers = 4,               # Number of parallel workers   plan = \"multisession\",     # Options: \"multisession\" or \"multicore\"   beep = TRUE,               # Enable sound notifications   chunk_size = 4L,           # Number of prompts to process in parallel at a time    max_chunk_attempts = 3L,   # Maximum retries for failed chunks   max_retries = 3,           # Maximum retry attempts   initial_delay = 20,        # Initial retry delay in seconds   max_delay = 60,            # Maximum delay between retries   backoff_factor = 2,        # Retry backoff multiplier   timeout = 60,              # Maximum seconds to wait for response   ...                        # Pass parameters to the chat model )"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"batchbatch","dir":"","previous_headings":"Quick References","what":"batch$batch()","title":"Batch Processing for Chat Models","text":"Processes list vector prompts. can mimic sequential processing using chat_future() setting chunk_size = 1, likely decrease performance compared chat_sequential() (see tests/manual/test-benchmark.R).","code":"batch(   prompts,                                  # List of prompts to process   type_spec = NULL,                         # Type specification for structured data   state_path = tempfile(\"chat_sequential_\",      # Path for state persistence                         fileext = \".rds\"),   chunk_size = 4                            # Number of prompts per chunk (parallel only) )"},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"results-methods","dir":"","previous_headings":"Quick References","what":"Results Methods","title":"Batch Processing for Chat Models","text":"texts(): Returns response texts format input prompts (.e., list prompts provided list, character vector prompts provided vector) chats(): Returns list chat objects progress(): Returns processing statistics structured_data(): Returns extracted structured data (type_spec provided)","code":""},{"path":"https://dylanpieper.github.io/hellmer/index.html","id":"further-reading","dir":"","previous_headings":"","what":"Further Reading","title":"Batch Processing for Chat Models","text":"Using Ellmer Chat Models: wondering can use chat_claude() user-defined object instead chat_claude function? course can! Learn two methods default interface. Comparing Packages Batching LLM Tasks","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Batch class for managing chat processing — batch","title":"Batch class for managing chat processing — batch","text":"Batch class managing chat processing","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Batch class for managing chat processing — batch","text":"","code":"batch(   prompts = list(),   responses = list(),   completed = integer(0),   state_path = character(0),   type_spec = NULL,   echo = character(0),   input_type = character(0),   max_retries = integer(0),   initial_delay = integer(0),   max_delay = integer(0),   backoff_factor = integer(0),   chunk_size = integer(0),   workers = integer(0),   plan = character(0),   state = list() )"},{"path":"https://dylanpieper.github.io/hellmer/reference/batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Batch class for managing chat processing — batch","text":"prompts List prompts process responses List store responses completed Integer indicating number completed prompts state_path Path save state file type_spec Type specification structured data extraction echo Level output display (\"none\", \"text\", \"\") input_type Type input (\"vector\" \"list\") max_retries Maximum number retry attempts initial_delay Initial delay first retry max_delay Maximum delay retries backoff_factor Factor multiply delay retry chunk_size Size chunks parallel processing workers Number parallel workers plan Parallel backend plan state Internal state tracking","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/capture.html","id":null,"dir":"Reference","previous_headings":"","what":"Capture chat model response with proper handling — capture","title":"Capture chat model response with proper handling — capture","text":"Capture chat model response proper handling","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/capture.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Capture chat model response with proper handling — capture","text":"","code":"capture(original_chat, prompt, type_spec = NULL, echo = \"text\")"},{"path":"https://dylanpieper.github.io/hellmer/reference/capture.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Capture chat model response with proper handling — capture","text":"original_chat Original chat model object prompt Prompt text type_spec Type specification structured data echo Echo level (\"none\", \"text\", \"\")","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/capture.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Capture chat model response with proper handling — capture","text":"List containing response information","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/capture_with_retry.html","id":null,"dir":"Reference","previous_headings":"","what":"Capture chat model response with proper handling and retries — capture_with_retry","title":"Capture chat model response with proper handling and retries — capture_with_retry","text":"Capture chat model response proper handling retries","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/capture_with_retry.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Capture chat model response with proper handling and retries — capture_with_retry","text":"","code":"capture_with_retry(   original_chat,   prompt,   type_spec = NULL,   echo = \"text\",   max_retries = 3L,   initial_delay = 1,   max_delay = 32,   backoff_factor = 2,   timeout = 60 )"},{"path":"https://dylanpieper.github.io/hellmer/reference/capture_with_retry.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Capture chat model response with proper handling and retries — capture_with_retry","text":"original_chat Original chat model object prompt Prompt text type_spec Type specification structured data echo Echo level (\"none\", \"text\", \"\") max_retries Maximum number retry attempts initial_delay Initial delay seconds first retry max_delay Maximum delay seconds retries backoff_factor Factor multiply delay retry","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/capture_with_retry.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Capture chat model response with proper handling and retries — capture_with_retry","text":"List containing response information","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_future.html","id":null,"dir":"Reference","previous_headings":"","what":"Process a batch of prompts in parallel — chat_future","title":"Process a batch of prompts in parallel — chat_future","text":"Processes batch chat prompts using parallel workers. Splits prompts chunks processing maintaining state. sequential processing, use chat_sequential().","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_future.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process a batch of prompts in parallel — chat_future","text":"","code":"chat_future(   chat_model = ellmer::chat_claude,   workers = 4,   plan = \"multisession\",   beep = TRUE,   chunk_size = 4L,   max_chunk_attempts = 3L,   max_retries = 3L,   initial_delay = 20,   max_delay = 60,   backoff_factor = 2,   timeout = 60,   ... )"},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_future.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process a batch of prompts in parallel — chat_future","text":"chat_model Chat model function/object (default: ellmer::chat_claude) workers Number parallel workers use (default: 4) plan Processing strategy use: \"multisession\" separate R sessions \"multicore\" forked processes (default: \"multisession\") beep Logical play sound batch completion, interruption, error (default: TRUE) chunk_size Number prompts process parallel time (default: 4) max_chunk_attempts Maximum number retry attempts failed chunks (default: 3) max_retries Maximum number retry attempts per prompt (default: 3) initial_delay Initial delay seconds first retry (default: 20) max_delay Maximum delay seconds retries (default: 60) backoff_factor Factor multiply delay retry (default: 2) timeout Maximum time seconds wait prompt response (default: 2) ... Additional arguments passed chat model","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_future.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process a batch of prompts in parallel — chat_future","text":"batch results object containing: prompts: Original input prompts responses: Raw response data completed prompts completed: Number successfully processed prompts state_path: Path batch state saved type_spec: Type specification used structured data texts: Function extract text responses chats: Function extract chat objects progress: Function get processing status structured_data: Function extract structured data (type_spec provided)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_sequential.html","id":null,"dir":"Reference","previous_headings":"","what":"Process a batch of prompts in sequence — chat_sequential","title":"Process a batch of prompts in sequence — chat_sequential","text":"Processes batch chat prompts one time sequential order. Maintains state runs can resume interrupted processing. parallel processing, use chat_future().","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_sequential.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process a batch of prompts in sequence — chat_sequential","text":"","code":"chat_sequential(   chat_model = ellmer::chat_claude,   echo = \"none\",   beep = TRUE,   max_retries = 3L,   initial_delay = 20,   max_delay = 60,   backoff_factor = 2,   timeout = 60,   ... )"},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_sequential.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process a batch of prompts in sequence — chat_sequential","text":"chat_model Chat model function/object (default: ellmer::chat_claude) echo Level output display: \"none\" silent operation, \"text\" response text , \"\" full interaction (default: \"none\") beep Logical play sound batch completion, interruption, error (default: TRUE) max_retries Maximum number retry attempts per prompt (default: 3) initial_delay Initial delay seconds first retry (default: 20) max_delay Maximum delay seconds retries (default: 60) backoff_factor Factor multiply delay retry (default: 2) timeout Maximum time seconds wait prompt response (default: 60) ... Additional arguments passed underlying chat model","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chat_sequential.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process a batch of prompts in sequence — chat_sequential","text":"batch results object containing: prompts: Original input prompts responses: Raw response data completed prompts completed: Number successfully processed prompts state_path: Path batch state saved type_spec: Type specification used structured data texts: Function extract text responses chats: Function extract chat objects progress: Function get processing status structured_data: Function extract structured data (type_spec provided)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chats.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract chat objects from a batch result — chats","title":"Extract chat objects from a batch result — chats","text":"Extract chat objects batch result Extract chat objects batch result","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chats.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract chat objects from a batch result — chats","text":"","code":"chats(x, ...)"},{"path":"https://dylanpieper.github.io/hellmer/reference/chats.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract chat objects from a batch result — chats","text":"x batch object ... Additional arguments passed methods","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/chats.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract chat objects from a batch result — chats","text":"list chat objects list chat objects","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/create_auth_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a standardized authentication error — create_auth_error","title":"Create a standardized authentication error — create_auth_error","text":"Create standardized authentication error","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/create_auth_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a standardized authentication error — create_auth_error","text":"","code":"create_auth_error(original_error)"},{"path":"https://dylanpieper.github.io/hellmer/reference/create_auth_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a standardized authentication error — create_auth_error","text":"original_error Original error message condition","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/create_auth_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a standardized authentication error — create_auth_error","text":"Structured error information","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/create_results.html","id":null,"dir":"Reference","previous_headings":"","what":"Create results object from batch — create_results","title":"Create results object from batch — create_results","text":"Create results object batch","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/create_results.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create results object from batch — create_results","text":"","code":"create_results(result)"},{"path":"https://dylanpieper.github.io/hellmer/reference/create_results.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create results object from batch — create_results","text":"result Batch object","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/create_results.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create results object from batch — create_results","text":"Results object class \"batch\"","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/finish_successful_batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Finish successful batch processing — finish_successful_batch","title":"Finish successful batch processing — finish_successful_batch","text":"Called successful completion batch processing update progress indicators provide feedback","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/finish_successful_batch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finish successful batch processing — finish_successful_batch","text":"","code":"finish_successful_batch(pb, beep)"},{"path":"https://dylanpieper.github.io/hellmer/reference/finish_successful_batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finish successful batch processing — finish_successful_batch","text":"pb Progress bar object beep Logical; whether play success sound","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/finish_successful_batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Finish successful batch processing — finish_successful_batch","text":"NULL (invisibly)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/handle_batch_interrupt.html","id":null,"dir":"Reference","previous_headings":"","what":"Handle batch interruption — handle_batch_interrupt","title":"Handle batch interruption — handle_batch_interrupt","text":"Handle batch interruption","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/handle_batch_interrupt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Handle batch interruption — handle_batch_interrupt","text":"","code":"handle_batch_interrupt(result, beep)"},{"path":"https://dylanpieper.github.io/hellmer/reference/handle_batch_interrupt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Handle batch interruption — handle_batch_interrupt","text":"result batch object containing processing state beep Logical indicating whether play sound","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/handle_batch_interrupt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Handle batch interruption — handle_batch_interrupt","text":"NULL (called side effects)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/hellmer-package.html","id":null,"dir":"Reference","previous_headings":"","what":"hellmer: Batch Processing for Chat Models — hellmer-package","title":"hellmer: Batch Processing for Chat Models — hellmer-package","text":"package enables sequential parallel batch processing chat models 'ellmer'.","code":""},{"path":[]},{"path":"https://dylanpieper.github.io/hellmer/reference/hellmer-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"hellmer: Batch Processing for Chat Models — hellmer-package","text":"Maintainer: Dylan Pieper dylanpieper@gmail.com","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/is_auth_error.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if an error is an authentication error — is_auth_error","title":"Check if an error is an authentication error — is_auth_error","text":"Check error authentication error","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/is_auth_error.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if an error is an authentication error — is_auth_error","text":"","code":"is_auth_error(error)"},{"path":"https://dylanpieper.github.io/hellmer/reference/is_auth_error.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if an error is an authentication error — is_auth_error","text":"error Error message condition","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/is_auth_error.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if an error is an authentication error — is_auth_error","text":"TRUE authentication error, FALSE otherwise","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process.html","id":null,"dir":"Reference","previous_headings":"","what":"Process batch of prompts with progress tracking and retries — process","title":"Process batch of prompts with progress tracking and retries — process","text":"Process batch prompts progress tracking retries","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process batch of prompts with progress tracking and retries — process","text":"","code":"process(   chat_obj,   prompts,   type_spec = NULL,   state_path = tempfile(\"chat_batch_\", fileext = \".rds\"),   echo = \"none\",   beep = TRUE,   max_retries = 3L,   initial_delay = 1,   max_delay = 32,   backoff_factor = 2,   timeout = 60 )"},{"path":"https://dylanpieper.github.io/hellmer/reference/process.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process batch of prompts with progress tracking and retries — process","text":"chat_obj Chat model object prompts List prompts type_spec Type specification structured data state_path Path saving state echo Echo level (\"none\", \"text\", \"\") beep Play sound completion, interruption, error max_retries Maximum number retry attempts per prompt initial_delay Initial delay seconds first retry max_delay Maximum delay seconds retries backoff_factor Factor multiply delay retry timeout Maximum time seconds wait prompt response","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process batch of prompts with progress tracking and retries — process","text":"Batch results object","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_chunks.html","id":null,"dir":"Reference","previous_headings":"","what":"Process chunks of prompts in parallel — process_chunks","title":"Process chunks of prompts in parallel — process_chunks","text":"Process chunks prompts parallel","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_chunks.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process chunks of prompts in parallel — process_chunks","text":"","code":"process_chunks(chunks, result, chat_obj, type_spec, pb, state_path, echo, beep)"},{"path":"https://dylanpieper.github.io/hellmer/reference/process_chunks.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process chunks of prompts in parallel — process_chunks","text":"chunks List prompt chunks process result batch object store results chat_obj Chat model object making API calls type_spec Type specification structured data extraction pb Progress bar object state_path Path save intermediate state echo Level output display (\"none\", \"text\", \"\") beep Logical indicating whether play sounds","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_chunks.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process chunks of prompts in parallel — process_chunks","text":"Updated batch object processed results","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_parallel.html","id":null,"dir":"Reference","previous_headings":"","what":"Process prompts in parallel chunks with error handling and state management — process_parallel","title":"Process prompts in parallel chunks with error handling and state management — process_parallel","text":"Process prompts parallel chunks error handling state management","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_parallel.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process prompts in parallel chunks with error handling and state management — process_parallel","text":"","code":"process_parallel(   chat_obj,   prompts,   type_spec = NULL,   state_path = tempfile(\"chat_batch_\", fileext = \".rds\"),   workers = 4,   chunk_size = 4,   plan = \"multisession\",   beep = TRUE,   timeout = 60,   max_chunk_attempts = 3L,   max_retries = 3L,   initial_delay = 1,   max_delay = 32,   backoff_factor = 2 )"},{"path":"https://dylanpieper.github.io/hellmer/reference/process_parallel.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process prompts in parallel chunks with error handling and state management — process_parallel","text":"chat_obj Chat model object API calls prompts Vector list prompts process type_spec Optional type specification structured data extraction state_path Path save intermediate state workers Number parallel workers (default: 4) chunk_size Number prompts per chunk (default: 4) plan Parallel backend: \"multisession\" \"multicore\" beep Play sound completion/error (default: TRUE) timeout Maximum seconds per prompt (default: 60) max_chunk_attempts Maximum retries per failed chunk (default: 3) max_retries Maximum retries per prompt (default: 3) initial_delay Initial delay first retry (default: 1) max_delay Maximum delay retries (default: 32) backoff_factor Delay multiplier retry (default: 2)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/process_parallel.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process prompts in parallel chunks with error handling and state management — process_parallel","text":"Batch results object containing processed responses","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract progress information from a batch — progress.batch","title":"Extract progress information from a batch — progress.batch","text":"Extract progress information batch","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract progress information from a batch — progress.batch","text":"x batch object","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract progress information from a batch — progress.batch","text":"list containing progress details","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.html","id":null,"dir":"Reference","previous_headings":"","what":"Get progress information from a batch result — progress","title":"Get progress information from a batch result — progress","text":"Get progress information batch result","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get progress information from a batch result — progress","text":"","code":"progress(x, ...)"},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get progress information from a batch result — progress","text":"x batch object ... Additional arguments passed methods","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/progress.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get progress information from a batch result — progress","text":"list containing progress details","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/structured_data.batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract structured data from a batch — structured_data.batch","title":"Extract structured data from a batch — structured_data.batch","text":"Extract structured data batch","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/structured_data.batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract structured data from a batch — structured_data.batch","text":"x batch object","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/structured_data.batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract structured data from a batch — structured_data.batch","text":"List structured data","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/structured_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract structured data from a batch result — structured_data","title":"Extract structured data from a batch result — structured_data","text":"Extract structured data batch result","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/structured_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract structured data from a batch result — structured_data","text":"","code":"structured_data(x, ...)"},{"path":"https://dylanpieper.github.io/hellmer/reference/structured_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract structured data from a batch result — structured_data","text":"x batch object ... Additional arguments passed methods","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/structured_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract structured data from a batch result — structured_data","text":"list structured data objects","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.batch.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract text responses from a batch — texts.batch","title":"Extract text responses from a batch — texts.batch","text":"Extract text responses batch","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.batch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract text responses from a batch — texts.batch","text":"x batch object","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.batch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract text responses from a batch — texts.batch","text":"character vector (original prompts supplied vector) list response texts (original prompts supplied list)","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract texts from a batch result — texts","title":"Extract texts from a batch result — texts","text":"Extract texts batch result","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract texts from a batch result — texts","text":"","code":"texts(x, ...)"},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract texts from a batch result — texts","text":"x batch object ... Additional arguments passed methods","code":""},{"path":"https://dylanpieper.github.io/hellmer/reference/texts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract texts from a batch result — texts","text":"character vector list text responses","code":""}]
